{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:19:38.316331Z",
     "iopub.status.busy": "2022-03-27T11:19:38.315603Z",
     "iopub.status.idle": "2022-03-27T11:19:43.486207Z",
     "shell.execute_reply": "2022-03-27T11:19:43.485025Z",
     "shell.execute_reply.started": "2022-03-27T11:19:38.316288Z"
    },
    "id": "RkmF-2BXy4-I",
    "outputId": "9715ec44-028c-4e65-8873-2b901934ddd2"
   },
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZ7OwnIe4CI1",
    "outputId": "297d3b4f-bde0-4279-dc81-ddee54ffdd9b"
   },
   "outputs": [],
   "source": [
    "!tar -xzvf \"./imagenette2-160.tgz\" -C \".\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:19:46.509213Z",
     "iopub.status.busy": "2022-03-27T11:19:46.508934Z",
     "iopub.status.idle": "2022-03-27T11:19:58.675111Z",
     "shell.execute_reply": "2022-03-27T11:19:58.673876Z",
     "shell.execute_reply.started": "2022-03-27T11:19:46.509172Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:19:58.679238Z",
     "iopub.status.busy": "2022-03-27T11:19:58.678858Z",
     "iopub.status.idle": "2022-03-27T11:20:02.478741Z",
     "shell.execute_reply": "2022-03-27T11:20:02.477723Z",
     "shell.execute_reply.started": "2022-03-27T11:19:58.679188Z"
    },
    "id": "8wzifRBL6ctz"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "import random\n",
    "from time import time\n",
    "from copy import deepcopy\n",
    "#from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "import cv2\n",
    "from torchvision.utils import make_grid \n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import os\n",
    "import gc\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "from torchvision import transforms\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.models as tm\n",
    "\n",
    "from matplotlib import colors, pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# в sklearn не все гладко, чтобы в colab удобно выводить картинки \n",
    "# мы будем игнорировать warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:20:02.481391Z",
     "iopub.status.busy": "2022-03-27T11:20:02.480849Z",
     "iopub.status.idle": "2022-03-27T11:20:02.532994Z",
     "shell.execute_reply": "2022-03-27T11:20:02.531535Z",
     "shell.execute_reply.started": "2022-03-27T11:20:02.481345Z"
    },
    "id": "uMeilYNFHKUw"
   },
   "outputs": [],
   "source": [
    "# разные режимы датасета \n",
    "DATA_MODES = ['train', 'val', 'test']\n",
    "# все изображения будут масштабированы к размеру 64x64 px\n",
    "RESCALE_SIZE = 64\n",
    "# работаем на видеокарте\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:20:02.534824Z",
     "iopub.status.busy": "2022-03-27T11:20:02.53444Z",
     "iopub.status.idle": "2022-03-27T11:20:02.564177Z",
     "shell.execute_reply": "2022-03-27T11:20:02.562965Z",
     "shell.execute_reply.started": "2022-03-27T11:20:02.53478Z"
    },
    "id": "5NrvWnmhET5V"
   },
   "outputs": [],
   "source": [
    "class ImageNetteDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Датасет с картинками, который паралельно подгружает их из папок\n",
    "    производит скалирование и превращение в торчевые тензоры\n",
    "    \"\"\"\n",
    "    def __init__(self, files, mode, part=1):\n",
    "        super().__init__()\n",
    "        # список файлов для загрузки\n",
    "        self.files = sorted(files)\n",
    "        # режим работы\n",
    "        self.mode = mode\n",
    "        self.part = part\n",
    "\n",
    "        if self.mode not in DATA_MODES:\n",
    "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
    "            raise NameError\n",
    "\n",
    "        self.len_ = len(self.files)\n",
    "     \n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            self.labels = [path.parent.name for path in self.files]\n",
    "            self.label_encoder.fit(self.labels)\n",
    "\n",
    "            with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
    "                  pickle.dump(self.label_encoder, le_dump_file)\n",
    "                      \n",
    "    def __len__(self):\n",
    "        return self.len_\n",
    "      \n",
    "    def load_sample(self, file):\n",
    "        image = Image.open(file)\n",
    "        image.load()\n",
    "        return image\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
    "        aug_transform = transforms.Compose([ # трансформации для аугментации\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(8),                        \n",
    "        ])\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "        ])\n",
    "        x = self.load_sample(self.files[index])\n",
    "        x = aug_transform(x)\n",
    "        x = self._prepare_sample(x)\n",
    "        x = np.array(x / 255, dtype='float32')\n",
    "        if len(x.shape) < 3: # в датасете картинки некоторые чернобелые и там отсутствует размерность каналов\n",
    "            x = np.expand_dims(x, axis=2)\n",
    "            x = np.repeat(x, 3, axis=2)\n",
    "        x = transform(x)\n",
    "        if self.mode == 'test':\n",
    "            return x\n",
    "        else:\n",
    "            label = self.labels[index]\n",
    "            label_id = self.label_encoder.transform([label])\n",
    "            y = label_id.item()\n",
    "            if self.part == 1:\n",
    "                return x, y\n",
    "            elif self.part == 2:\n",
    "                return x, y + 2\n",
    "            elif self.part == 3:\n",
    "                return x, y + 4\n",
    "            elif self.part == 4:\n",
    "                return x, y + 6\n",
    "            elif self.part == 5:\n",
    "                return x, y + 8\n",
    "    def _prepare_sample(self, image):\n",
    "        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n",
    "        return np.array(image)\n",
    "\n",
    "#функция для балансировки классов\n",
    "def make_weights_for_balanced_classes(images, nclasses):                    \n",
    "    count = [0] * nclasses                                                      \n",
    "    for item in images:                                                         \n",
    "        count[item[1]] += 1                                                     \n",
    "    weight_per_class = [0.] * nclasses                                      \n",
    "    N = float(sum(count))                                                   \n",
    "    for i in range(nclasses):                                                   \n",
    "        weight_per_class[i] = N/float(count[i])                                 \n",
    "    weight = [0] * len(images)                                              \n",
    "    for idx, val in enumerate(images):                                          \n",
    "        weight[idx] = weight_per_class[val[1]]                                  \n",
    "    return weight\n",
    "\n",
    "def imshow(inp, title=None, plt_ax=plt, default=False):\n",
    "    \"\"\"Imshow для тензоров\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    #mean = np.array([0.485, 0.456, 0.406])\n",
    "    #std = np.array([0.229, 0.224, 0.225])\n",
    "    #inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt_ax.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt_ax.set_title(title)\n",
    "    plt_ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:20:02.568441Z",
     "iopub.status.busy": "2022-03-27T11:20:02.568182Z",
     "iopub.status.idle": "2022-03-27T11:20:02.579142Z",
     "shell.execute_reply": "2022-03-27T11:20:02.578025Z",
     "shell.execute_reply.started": "2022-03-27T11:20:02.56841Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.getcwd() == '/kaggle/working':\n",
    "    os.chdir('./imagenette2-160')\n",
    "    \n",
    "dir_names = {\n",
    "    0: 'n01440764',\n",
    "    1: 'n02102040',\n",
    "    2: 'n02979186',\n",
    "    3: 'n03000684',\n",
    "    4: 'n03028079',\n",
    "    5: 'n03394916',\n",
    "    6: 'n03417042',\n",
    "    7: 'n03425413',\n",
    "    8: 'n03445777',\n",
    "    9: 'n03888257',\n",
    "}    \n",
    "\n",
    "#for i in range(1,5):\n",
    "#    if not os.path.isdir('generated' + '_' + str(i)):\n",
    "#        os.mkdir('generated' + '_' + str(i))\n",
    "#    for j in range(10):\n",
    "#        if not os.path.isdir('generated'+ '_' + str(i) + '/' + dir_names[j]):\n",
    "#            os.mkdir('generated'+ '_' + str(i) + '/' + dir_names[j])\n",
    "\n",
    "#if not os.path.isdir('generated'):\n",
    "#    os.mkdir('generated')\n",
    "#for j in range(10):\n",
    "#    if not os.path.isdir('generated/' + dir_names[j]):\n",
    "#        os.mkdir('generated/'+dir_names[j])\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:20:02.581439Z",
     "iopub.status.busy": "2022-03-27T11:20:02.58117Z",
     "iopub.status.idle": "2022-03-27T11:20:02.783484Z",
     "shell.execute_reply": "2022-03-27T11:20:02.782441Z",
     "shell.execute_reply.started": "2022-03-27T11:20:02.581408Z"
    },
    "id": "jS1awKlVuK4G"
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = Path('./train')\n",
    "TEST_DIR = Path('./val')\n",
    "\n",
    "train_files = list(TRAIN_DIR.rglob('*.JPEG'))\n",
    "val_files = list(TEST_DIR.rglob('*.JPEG'))\n",
    "train_val_files = sorted(train_files + val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:20:02.788038Z",
     "iopub.status.busy": "2022-03-27T11:20:02.787385Z",
     "iopub.status.idle": "2022-03-27T11:20:02.871258Z",
     "shell.execute_reply": "2022-03-27T11:20:02.870251Z",
     "shell.execute_reply.started": "2022-03-27T11:20:02.787987Z"
    },
    "id": "iMf-jqPOucby"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_labels = [path.parent.name for path in train_val_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:20:11.204519Z",
     "iopub.status.busy": "2022-03-27T11:20:11.203556Z",
     "iopub.status.idle": "2022-03-27T11:20:11.336139Z",
     "shell.execute_reply": "2022-03-27T11:20:11.335068Z",
     "shell.execute_reply.started": "2022-03-27T11:20:11.204468Z"
    }
   },
   "outputs": [],
   "source": [
    "train_val_labels_1 = train_val_labels[:1918] + train_val_labels[9469:10251]\n",
    "train_val_labels_2 = train_val_labels[1918:3769] + train_val_labels[10251:10994]\n",
    "train_val_labels_3 = train_val_labels[3769:5666] + train_val_labels[10994:11797]\n",
    "train_val_labels_4 = train_val_labels[5666:7558] + train_val_labels[11797:12605]\n",
    "train_val_labels_5 = train_val_labels[7558:9469] + train_val_labels[12605:]    \n",
    "\n",
    "train_val_files_1 = train_val_files[:1918] + train_val_files[9469:10251]\n",
    "train_val_files_2 = train_val_files[1918:3769] + train_val_files[10251:10994]\n",
    "train_val_files_3 = train_val_files[3769:5666] + train_val_files[10994:11797]\n",
    "train_val_files_4 = train_val_files[5666:7558] + train_val_files[11797:12605]\n",
    "train_val_files_5 = train_val_files[7558:9469] + train_val_files[12605:]    \n",
    "\n",
    "train_files_1, val_files_1 = train_test_split(train_val_files_1, test_size=0.2, stratify=train_val_labels_1)\n",
    "train_files_2, val_files_2 = train_test_split(train_val_files_2, test_size=0.2, stratify=train_val_labels_2)\n",
    "train_files_3, val_files_3 = train_test_split(train_val_files_3, test_size=0.2, stratify=train_val_labels_3)\n",
    "train_files_4, val_files_4 = train_test_split(train_val_files_4, test_size=0.2, stratify=train_val_labels_4)\n",
    "train_files_5, val_files_5 = train_test_split(train_val_files_5, test_size=0.2, stratify=train_val_labels_5)\n",
    "\n",
    "train_dataset_1 = ImageNetteDataset(train_files_1, mode='train', part=1)\n",
    "#train_dataset_2 = ImageNetteDataset(train_files_2, mode='train', part=2)\n",
    "#train_dataset_3 = ImageNetteDataset(train_files_3, mode='train', part=3)\n",
    "#train_dataset_4 = ImageNetteDataset(train_files_4, mode='train', part=4)\n",
    "#train_dataset_5 = ImageNetteDataset(train_files_5, mode='train', part=5)\n",
    "\n",
    "val_dataset_1 = ImageNetteDataset(val_files_1, mode='val')\n",
    "val_dataset_2 = ImageNetteDataset(val_files_1 + val_files_2, mode='val')\n",
    "val_dataset_3 = ImageNetteDataset(val_files_1 + val_files_2 + val_files_3, mode='val')\n",
    "val_dataset_4 = ImageNetteDataset(val_files_1 + val_files_2 + val_files_3 + val_files_4, mode='val')\n",
    "val_dataset_5 = ImageNetteDataset(val_files_1 + val_files_2 + val_files_3 + val_files_4 + val_files_5, mode='val')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:20:13.484336Z",
     "iopub.status.busy": "2022-03-27T11:20:13.484026Z",
     "iopub.status.idle": "2022-03-27T11:20:13.58041Z",
     "shell.execute_reply": "2022-03-27T11:20:13.57929Z",
     "shell.execute_reply.started": "2022-03-27T11:20:13.484305Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_2 = ImageNetteDataset(train_files_2, mode='train', part=2)\n",
    "train_dataset_3 = ImageNetteDataset(train_files_3, mode='train', part=3)\n",
    "train_dataset_4 = ImageNetteDataset(train_files_4, mode='train', part=4)\n",
    "train_dataset_5 = ImageNetteDataset(train_files_5, mode='train', part=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:20:15.4164Z",
     "iopub.status.busy": "2022-03-27T11:20:15.416069Z",
     "iopub.status.idle": "2022-03-27T11:20:15.428087Z",
     "shell.execute_reply": "2022-03-27T11:20:15.426701Z",
     "shell.execute_reply.started": "2022-03-27T11:20:15.416368Z"
    }
   },
   "outputs": [],
   "source": [
    "len(val_files_1+val_files_2+val_files_3+val_files_4+val_files_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:20:17.00913Z",
     "iopub.status.busy": "2022-03-27T11:20:17.008591Z",
     "iopub.status.idle": "2022-03-27T11:20:20.877616Z",
     "shell.execute_reply": "2022-03-27T11:20:20.876712Z",
     "shell.execute_reply.started": "2022-03-27T11:20:17.009092Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=5, ncols=5, figsize=(12, 12), \\\n",
    "                        sharey=True, sharex=True)\n",
    "for fig_x in ax.flatten():\n",
    "    random_characters = int(np.random.uniform(0,540))\n",
    "    im_val, label = val_dataset_1[random_characters]\n",
    "    #img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
    "    #            second_val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
    "    imshow(im_val.data.cpu(), \\\n",
    "          title=label,plt_ax=fig_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:20:20.880132Z",
     "iopub.status.busy": "2022-03-27T11:20:20.879454Z",
     "iopub.status.idle": "2022-03-27T11:20:25.042311Z",
     "shell.execute_reply": "2022-03-27T11:20:25.041513Z",
     "shell.execute_reply.started": "2022-03-27T11:20:20.880063Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=5, ncols=5, figsize=(12, 12), \\\n",
    "                        sharey=True, sharex=True)\n",
    "for fig_x in ax.flatten():\n",
    "    random_characters = int(np.random.uniform(0,1059))\n",
    "    im_val, label = val_dataset_2[random_characters]\n",
    "    #img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
    "    #            second_val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
    "    imshow(im_val.data.cpu(), \\\n",
    "          title=label,plt_ax=fig_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:20:25.044731Z",
     "iopub.status.busy": "2022-03-27T11:20:25.044074Z",
     "iopub.status.idle": "2022-03-27T11:20:28.768547Z",
     "shell.execute_reply": "2022-03-27T11:20:28.767529Z",
     "shell.execute_reply.started": "2022-03-27T11:20:25.044664Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=5, ncols=5, figsize=(12, 12), \\\n",
    "                        sharey=True, sharex=True)\n",
    "for fig_x in ax.flatten():\n",
    "    random_characters = int(np.random.uniform(0,1599))\n",
    "    im_val, label = val_dataset_3[random_characters]\n",
    "    #img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
    "    #            second_val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
    "    imshow(im_val.data.cpu(), \\\n",
    "          title=label,plt_ax=fig_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:20:28.772534Z",
     "iopub.status.busy": "2022-03-27T11:20:28.771336Z",
     "iopub.status.idle": "2022-03-27T11:20:32.491433Z",
     "shell.execute_reply": "2022-03-27T11:20:32.490616Z",
     "shell.execute_reply.started": "2022-03-27T11:20:28.772483Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=5, ncols=5, figsize=(12, 12), \\\n",
    "                        sharey=True, sharex=True)\n",
    "for fig_x in ax.flatten():\n",
    "    random_characters = int(np.random.uniform(0,2139))\n",
    "    im_val, label = val_dataset_4[random_characters]\n",
    "    #img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
    "    #            val_dataset_4.label_encoder.inverse_transform([label])[0].split('_')))\n",
    "    imshow(im_val.data.cpu(), \\\n",
    "          title=label,plt_ax=fig_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:20:32.494606Z",
     "iopub.status.busy": "2022-03-27T11:20:32.493504Z",
     "iopub.status.idle": "2022-03-27T11:20:36.342761Z",
     "shell.execute_reply": "2022-03-27T11:20:36.341769Z",
     "shell.execute_reply.started": "2022-03-27T11:20:32.494556Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=5, ncols=5, figsize=(12, 12), \\\n",
    "                        sharey=True, sharex=True)\n",
    "for fig_x in ax.flatten():\n",
    "    random_characters = int(np.random.uniform(0,2679))\n",
    "    im_val, label = val_dataset_5[random_characters]\n",
    "    #img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
    "    #            second_val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
    "    imshow(im_val.data.cpu(), \\\n",
    "          title=label,plt_ax=fig_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:20:36.345303Z",
     "iopub.status.busy": "2022-03-27T11:20:36.344216Z",
     "iopub.status.idle": "2022-03-27T11:20:36.354796Z",
     "shell.execute_reply": "2022-03-27T11:20:36.353246Z",
     "shell.execute_reply.started": "2022-03-27T11:20:36.345249Z"
    }
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "def save_generated(images, labels, count, number):\n",
    "    for i, img in enumerate(images):\n",
    "        #save_image(img, 'generated_' + str(number) + '/' + dir_names[int(labels[i])] + '/' + str(i) + '.JPEG')\n",
    "        save_image(img, 'generated/' + dir_names[int(labels[i])] + '/' + str(count) + '.JPEG')\n",
    "        count+=1\n",
    "    return count\n",
    "        \n",
    "def get_gen_files(number):\n",
    "    #gen_dir = Path('./generated_' + str(number))\n",
    "    gen_dir = Path('./generated')\n",
    "    gen_files = list(gen_dir.rglob('*.JPEG'))\n",
    "    return gen_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:20:36.357494Z",
     "iopub.status.busy": "2022-03-27T11:20:36.357038Z",
     "iopub.status.idle": "2022-03-27T11:20:48.931467Z",
     "shell.execute_reply": "2022-03-27T11:20:48.930255Z",
     "shell.execute_reply.started": "2022-03-27T11:20:36.35743Z"
    },
    "id": "wpChNpngvMyo",
    "outputId": "b062b165-708b-4090-b79c-17a9cb4df39b"
   },
   "outputs": [],
   "source": [
    "!pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:20:48.934941Z",
     "iopub.status.busy": "2022-03-27T11:20:48.934531Z",
     "iopub.status.idle": "2022-03-27T11:20:50.495944Z",
     "shell.execute_reply": "2022-03-27T11:20:50.494803Z",
     "shell.execute_reply.started": "2022-03-27T11:20:48.934889Z"
    },
    "id": "j_TVPC8cvnbg",
    "outputId": "efe317d0-c8d4-406f-896c-2dae649aa368"
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "efficient_net = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "\n",
    "num_features = 1280 #именно столько приходит на вход полносвязному слою\n",
    "out_features = 10\n",
    "\n",
    "efficient_net._fc = nn.Linear(num_features, out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:20:50.498481Z",
     "iopub.status.busy": "2022-03-27T11:20:50.497537Z",
     "iopub.status.idle": "2022-03-27T11:21:00.049525Z",
     "shell.execute_reply": "2022-03-27T11:21:00.048339Z",
     "shell.execute_reply.started": "2022-03-27T11:20:50.498434Z"
    }
   },
   "outputs": [],
   "source": [
    "summary(efficient_net, (3,64,64))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:21:00.054509Z",
     "iopub.status.busy": "2022-03-27T11:21:00.05347Z",
     "iopub.status.idle": "2022-03-27T11:21:00.910983Z",
     "shell.execute_reply": "2022-03-27T11:21:00.909691Z",
     "shell.execute_reply.started": "2022-03-27T11:21:00.054427Z"
    },
    "id": "Vd_-d5VRwcJB",
    "outputId": "3167d1ce-f373-429a-aa58-7c8eff34316d"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:21:00.914123Z",
     "iopub.status.busy": "2022-03-27T11:21:00.913728Z",
     "iopub.status.idle": "2022-03-27T11:21:00.933982Z",
     "shell.execute_reply": "2022-03-27T11:21:00.932849Z",
     "shell.execute_reply.started": "2022-03-27T11:21:00.91407Z"
    },
    "id": "7JySQ2kbwd1K",
    "outputId": "0c2a14ee-2d64-4b4c-bca0-13dba3b363cf"
   },
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(train_val_labels))\n",
    "efficient_net = efficient_net.to(device)\n",
    "print(\"we will classify :{}\".format(n_classes))\n",
    "#print(efficient_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:21:00.936673Z",
     "iopub.status.busy": "2022-03-27T11:21:00.93588Z",
     "iopub.status.idle": "2022-03-27T11:21:00.948705Z",
     "shell.execute_reply": "2022-03-27T11:21:00.947548Z",
     "shell.execute_reply.started": "2022-03-27T11:21:00.936629Z"
    },
    "id": "3vyj0Yriwxnn",
    "outputId": "09599d12-d940-41e2-f659-4d809da71585"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "count_parameters(efficient_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T10:01:24.684123Z",
     "iopub.status.busy": "2022-01-19T10:01:24.683596Z",
     "iopub.status.idle": "2022-01-19T10:01:24.750081Z",
     "shell.execute_reply": "2022-01-19T10:01:24.749318Z",
     "shell.execute_reply.started": "2022-01-19T10:01:24.68407Z"
    },
    "id": "7H7WcewTtUZg"
   },
   "outputs": [],
   "source": [
    "#torch.save(efficient_net.state_dict(), 'effnet_total.pth') # скор 0.9055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:21:00.951733Z",
     "iopub.status.busy": "2022-03-27T11:21:00.950348Z",
     "iopub.status.idle": "2022-03-27T11:21:00.960308Z",
     "shell.execute_reply": "2022-03-27T11:21:00.959023Z",
     "shell.execute_reply.started": "2022-03-27T11:21:00.951682Z"
    }
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:21:00.963571Z",
     "iopub.status.busy": "2022-03-27T11:21:00.96321Z",
     "iopub.status.idle": "2022-03-27T11:21:01.075313Z",
     "shell.execute_reply": "2022-03-27T11:21:01.074168Z",
     "shell.execute_reply.started": "2022-03-27T11:21:00.963524Z"
    },
    "id": "su2l79uiwRCn"
   },
   "outputs": [],
   "source": [
    "def variable(t: torch.Tensor, use_cuda=True, **kwargs): \n",
    "    if torch.cuda.is_available() and use_cuda:         \n",
    "        t = t.cuda()\n",
    "    return Variable(t, **kwargs)\n",
    "\n",
    "class EWC(object):\n",
    "    def __init__(self, old_x, old_y, model):\n",
    "\n",
    "        self.model = model\n",
    "        self.old_x = old_x\n",
    "        self.old_y = old_y\n",
    "        self.params = {n: p for n, p in self.model.named_parameters() if p.requires_grad}\n",
    "        self._old_params = {}\n",
    "        self._precision_matrices = self._diag_fisher() \n",
    "\n",
    "        for n, p in deepcopy(self.params).items():\n",
    "            self._old_params[n] = variable(p.data)\n",
    "\n",
    "\n",
    "    def _diag_fisher(self):\n",
    "        precision_matrices = {}\n",
    "        for n, p in deepcopy(self.params).items(): \n",
    "            p.data.zero_() \n",
    "            precision_matrices[n] = variable(p.data) \n",
    "\n",
    "        self.model.eval() \n",
    "        self.model.zero_grad() \n",
    "        self.old_x = variable(self.old_x) \n",
    "        output = self.model(self.old_x)\n",
    "        output = output.to(device)\n",
    "        loss = F.nll_loss(F.log_softmax(output, dim=1), self.old_y.to(device)) # возможно тут убрать лог софтмакс\n",
    "        loss.backward()\n",
    "\n",
    "        for n, p in self.model.named_parameters():\n",
    "            precision_matrices[n].data += p.grad.data ** 2 / len(self.old_x)\n",
    "\n",
    "        precision_matrices = {n: p for n, p in precision_matrices.items()}\n",
    "        return precision_matrices\n",
    "\n",
    "    def penalty(self, model: nn.Module):\n",
    "        loss = 0\n",
    "        for n, p in model.named_parameters():\n",
    "            _loss = self._precision_matrices[n].data * (p - self._old_params[n].data) ** 2\n",
    "            loss += _loss.sum()\n",
    "        return loss\n",
    "    \n",
    "\n",
    "def fit_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_data = 0\n",
    "    for inputs, labels in tqdm(train_loader, desc = \"iter:\", position=0, leave=True):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(inputs)\n",
    "        outputs = F.softmax(logits, dim=1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        preds = torch.argmax(logits, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        processed_data += inputs.size(0)\n",
    "              \n",
    "    train_loss = running_loss / processed_data\n",
    "    train_acc = running_corrects.cpu().numpy() / processed_data\n",
    "    return train_loss, train_acc  \n",
    "\n",
    "def fit_ewc_epoch(model, train_loader, criterion, optimizer, ewc, importance):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_data = 0\n",
    "    for inputs, labels in tqdm(train_loader, desc = \"iter:\", position=0, leave=True):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        inputs, labels = variable(inputs), variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels) + importance * ewc.penalty(model)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        processed_data += inputs.size(0)\n",
    "              \n",
    "    train_loss = running_loss / processed_data\n",
    "    train_acc = running_corrects.cpu().numpy() / processed_data\n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "def eval_epoch(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_size = 0\n",
    "\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            logits = model(inputs)\n",
    "            outputs = F.softmax(logits,dim=1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            preds = torch.argmax(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        processed_size += inputs.size(0)\n",
    "    val_loss = running_loss / processed_size\n",
    "    val_acc = running_corrects.double() / processed_size\n",
    "    return val_loss, val_acc\n",
    "    \n",
    "    \n",
    "    \n",
    "def train(train_dataset, model, epochs, number, batch_size):\n",
    "    best_acc = 0.0\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    best_model_weights = model.state_dict()\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    \n",
    "    if number == 1:\n",
    "        val_loader_1 = DataLoader(val_dataset_1, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    elif number == 2:\n",
    "        val_loader_1 = DataLoader(val_dataset_1, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        val_loader_2 = DataLoader(val_dataset_2, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    elif number == 3:\n",
    "        val_loader_1 = DataLoader(val_dataset_1, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        val_loader_2 = DataLoader(val_dataset_2, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        val_loader_3 = DataLoader(val_dataset_3, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    elif number == 4:\n",
    "        val_loader_1 = DataLoader(val_dataset_1, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        val_loader_2 = DataLoader(val_dataset_2, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        val_loader_3 = DataLoader(val_dataset_3, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        val_loader_4 = DataLoader(val_dataset_4, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    elif number == 5:\n",
    "        val_loader_1 = DataLoader(val_dataset_1, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        val_loader_2 = DataLoader(val_dataset_2, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        val_loader_3 = DataLoader(val_dataset_3, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        val_loader_4 = DataLoader(val_dataset_4, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        val_loader_5 = DataLoader(val_dataset_5, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "    history = []\n",
    "\n",
    "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
    "        opt = torch.optim.Adam(model.parameters(), lr = 4e-4)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size = 3, gamma = 0.7)\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n",
    "            exp_lr_scheduler.step() #сюда добавили \"шедулер\"\n",
    "            \n",
    "            pbar_outer.update(1)\n",
    "            if number == 1:\n",
    "                val_loss_1, val_acc_1 = eval_epoch(model, val_loader_1, criterion)\n",
    "                history.append((train_loss, train_acc, val_loss_1, val_acc_1))\n",
    "                val_acc = val_acc_1\n",
    "                print('accuracy on 1:', val_acc_1)\n",
    "                print('total_accuracy:', val_acc)\n",
    "                tqdm.write(\"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
    "                            val_loss_1 {v_loss:0.4f} train_acc {t_acc:0.4f} \\\n",
    "                            val_acc_1 {v_acc:0.4f}\".format(ep=epoch+1, t_loss=train_loss,\n",
    "                                           v_loss=val_loss_1, t_acc=train_acc, v_acc=val_acc_1))\n",
    "\n",
    "            elif number == 2:\n",
    "                val_loss_1, val_acc_1 = eval_epoch(model, val_loader_1, criterion)\n",
    "                val_loss_2, val_acc_2 = eval_epoch(model, val_loader_2, criterion)\n",
    "                history.append((train_loss, train_acc, val_loss_1, val_acc_1, val_loss_2, val_acc_2))\n",
    "                val_acc = (val_acc_1 + val_acc_2)/2\n",
    "                print('accuracy on 1:', val_acc_1)\n",
    "                print('accuracy on 2:', val_acc_2)\n",
    "                print('total_accuracy:', val_acc)\n",
    "                tqdm.write(\"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
    "                            val_loss_1 {v_loss:0.4f} val_loss2 {v_loss2:0.4} train_acc {t_acc:0.4f} \\\n",
    "                            val_acc_1 {v_acc:0.4f} val_acc_2 {v_acc2:0.4f}\".format(ep=epoch+1, t_loss=train_loss,\n",
    "                                           v_loss=val_loss_1, v_loss2=val_loss_2, t_acc=train_acc, v_acc=val_acc_1, v_acc2=val_acc_2))\n",
    "\n",
    "            elif number == 3:\n",
    "                val_loss_1, val_acc_1 = eval_epoch(model, val_loader_1, criterion)\n",
    "                val_loss_2, val_acc_2 = eval_epoch(model, val_loader_2, criterion)\n",
    "                val_loss_3, val_acc_3 = eval_epoch(model, val_loader_3, criterion)\n",
    "                history.append((train_loss, train_acc, val_loss_1, val_acc_1, val_loss_2, val_acc_2, val_loss_3, val_acc_3))\n",
    "                print('accuracy on 1:', val_acc_1)\n",
    "                print('accuracy on 2:', val_acc_2)\n",
    "                print('accuracy on 3:', val_acc_3)\n",
    "                val_acc = (val_acc_1 + val_acc_2 + val_acc_3)/3\n",
    "                print('total_accuracy:', val_acc)\n",
    "                tqdm.write(\"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
    "                            val_loss_1 {v_loss:0.4f} val_loss_2 {v_loss2:0.4f} val_loss_3 {v_loss3:0.4f} \\\n",
    "                            train_acc {t_acc:0.4f} val_acc_1 {v_acc:0.4f} val_acc_2 {v_acc2:0.4f} val_acc_3 {v_acc3:0.4f}\\\n",
    "                            \".format(ep=epoch+1, t_loss=train_loss,\n",
    "                                           v_loss=val_loss_1, v_loss2=val_loss_2, v_loss3=val_loss_3,\n",
    "                                      t_acc=train_acc, v_acc=val_acc_1, v_acc2=val_acc_2, v_acc3=val_acc_3))  \n",
    "                      \n",
    "            elif number == 4:\n",
    "                val_loss_1, val_acc_1 = eval_epoch(model, val_loader_1, criterion)\n",
    "                val_loss_2, val_acc_2 = eval_epoch(model, val_loader_2, criterion)\n",
    "                val_loss_3, val_acc_3 = eval_epoch(model, val_loader_3, criterion)\n",
    "                val_loss_4, val_acc_4 = eval_epoch(model, val_loader_4, criterion)\n",
    "                history.append((train_loss, train_acc, val_loss_1, val_acc_1, val_loss_2, val_acc_2, val_loss_3, val_acc_3, val_loss_4, val_acc_4))\n",
    "                print('accuracy on 1:', val_acc_1)\n",
    "                print('accuracy on 2:', val_acc_2)\n",
    "                print('accuracy on 3:', val_acc_3)\n",
    "                print('accuracy on 4:', val_acc_4)\n",
    "                val_acc = (val_acc_1 + val_acc_2 + val_acc_3 + val_acc_4)/4\n",
    "                print('total_accuracy:', val_acc)\n",
    "                \n",
    "                tqdm.write(\"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
    "                            val_loss_1 {v_loss:0.4f} val_loss_2 {v_loss2:0.4f} val_loss_3 {v_loss3:0.4f} val_loss_4 {v_loss4:0.4f} \\\n",
    "                            train_acc {t_acc:0.4f} val_acc_1 {v_acc:0.4f} val_acc_2 {v_acc2:0.4f} val_acc_3 {v_acc3:0.4f} val_acc_4 {v_acc4:0.4f}\\\n",
    "                            \".format(ep=epoch+1, t_loss=train_loss,\n",
    "                                           v_loss=val_loss_1, v_loss2=val_loss_2, v_loss3=val_loss_3, v_loss4=val_loss_4,\n",
    "                                      t_acc=train_acc, v_acc=val_acc_1, v_acc2=val_acc_2, v_acc3=val_acc_3, v_acc4=val_acc_4))  \n",
    "              \n",
    "            elif number == 5:\n",
    "                val_loss_1, val_acc_1 = eval_epoch(model, val_loader_1, criterion)\n",
    "                val_loss_2, val_acc_2 = eval_epoch(model, val_loader_2, criterion)\n",
    "                val_loss_3, val_acc_3 = eval_epoch(model, val_loader_3, criterion)\n",
    "                val_loss_4, val_acc_4 = eval_epoch(model, val_loader_4, criterion)\n",
    "                val_loss_5, val_acc_5 = eval_epoch(model, val_loader_5, criterion)\n",
    "\n",
    "                history.append((train_loss, train_acc, val_loss_1, val_acc_1, val_loss_2, val_acc_2, val_loss_3, val_acc_3, val_loss_4, val_acc_4, val_loss_5, val_acc_5))\n",
    "                print('accuracy on 1:', val_acc_1)\n",
    "                print('accuracy on 2:', val_acc_2)\n",
    "                print('accuracy on 3:', val_acc_3)\n",
    "                print('accuracy on 4:', val_acc_4)\n",
    "                print('accuracy on 5:', val_acc_5)\n",
    "\n",
    "                val_acc = (val_acc_1 + val_acc_2 + val_acc_3 + val_acc_4+val_acc_5)/5\n",
    "                print('total_accuracy:', val_acc)\n",
    "                \n",
    "                tqdm.write(\"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
    "                            val_loss_1 {v_loss:0.4f} val_loss_2 {v_loss2:0.4f} val_loss_3 {v_loss3:0.4f} val_loss_4 {v_loss4:0.4f} val_loss_5 {v_loss5:0.4f}\\\n",
    "                            train_acc {t_acc:0.4f} val_acc_1 {v_acc:0.4f} val_acc_2 {v_acc2:0.4f} val_acc_3 {v_acc3:0.4f} val_acc_4 {v_acc4:0.4f} val_acc_5 {v_acc5:0.4f}\\\n",
    "                            \".format(ep=epoch+1, t_loss=train_loss,\n",
    "                                           v_loss=val_loss_1, v_loss2=val_loss_2, v_loss3=val_loss_3, v_loss4=val_loss_4, v_loss5=val_loss_5,\n",
    "                                      t_acc=train_acc, v_acc=val_acc_1, v_acc2=val_acc_2, v_acc3=val_acc_3, v_acc4=val_acc_4, v_acc5=val_acc_5))  \n",
    "            #добавим сохранение лучшей модели\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                best_model_weights = model.state_dict()\n",
    "    print('Best total accuracy:', best_acc)\n",
    "    model.load_state_dict(best_model_weights) #загрузим лучшую модель\n",
    "    return history\n",
    "\n",
    "def make_prev(dataset):\n",
    "    print(\"Making previous tensors\")\n",
    "    prev_X = dataset[0][0].unsqueeze(0)\n",
    "    prev_y = []\n",
    "    for i in tqdm(range(1, len(dataset))):\n",
    "        x, y = dataset[i]\n",
    "        prev_X = torch.cat((prev_X, x.unsqueeze(0)))\n",
    "        prev_y.append(y)\n",
    "    return prev_X, torch.as_tensor(prev_y)\n",
    "    \n",
    "\n",
    "\n",
    "def new_ewc_train(train_dataset, prev_dataset, model, epochs, number, batch_size, importance):\n",
    "    prev_loader = DataLoader(prev_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    best_model_weights = model.state_dict()\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    \n",
    "    if number == 1:\n",
    "        val_loader_1 = DataLoader(val_dataset_1, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    elif number == 2:\n",
    "        val_loader_1 = DataLoader(val_dataset_1, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        val_loader_2 = DataLoader(val_dataset_2, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    elif number == 3:\n",
    "        val_loader_1 = DataLoader(val_dataset_1, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        val_loader_2 = DataLoader(val_dataset_2, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        val_loader_3 = DataLoader(val_dataset_3, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    elif number == 4:\n",
    "        val_loader_1 = DataLoader(val_dataset_1, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        val_loader_2 = DataLoader(val_dataset_2, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        val_loader_3 = DataLoader(val_dataset_3, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        val_loader_4 = DataLoader(val_dataset_4, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    elif number == 5:\n",
    "        val_loader_1 = DataLoader(val_dataset_1, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        val_loader_2 = DataLoader(val_dataset_2, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        val_loader_3 = DataLoader(val_dataset_3, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        val_loader_4 = DataLoader(val_dataset_4, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        val_loader_5 = DataLoader(val_dataset_5, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "    history = []\n",
    "\n",
    "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
    "        opt = torch.optim.Adam(model.parameters(), lr = 4e-4)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size = 3, gamma = 0.7)\n",
    "        for epoch in range(epochs):\n",
    "            prev_X, prev_y = next(iter(prev_loader))\n",
    "            ewc = EWC(prev_X, prev_y, model)\n",
    "            train_loss, train_acc = fit_ewc_epoch(model, train_loader, criterion, opt, ewc, importance)\n",
    "            exp_lr_scheduler.step() #сюда добавили \"шедулер\"\n",
    "            pbar_outer.update(1)\n",
    "            if number == 1:\n",
    "                val_loss_1, val_acc_1 = eval_epoch(model, val_loader_1, criterion)\n",
    "                history.append((train_loss, train_acc, val_loss_1, val_acc_1))\n",
    "                val_acc = val_acc_1\n",
    "                print('accuracy on 1:', val_acc_1)\n",
    "                print('total_accuracy:', val_acc)\n",
    "                tqdm.write(\"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
    "                            val_loss_1 {v_loss:0.4f} train_acc {t_acc:0.4f} \\\n",
    "                            val_acc_1 {v_acc:0.4f}\".format(ep=epoch+1, t_loss=train_loss,\n",
    "                                           v_loss=val_loss_1, t_acc=train_acc, v_acc=val_acc_1))\n",
    "\n",
    "            elif number == 2:\n",
    "                val_loss_1, val_acc_1 = eval_epoch(model, val_loader_1, criterion)\n",
    "                val_loss_2, val_acc_2 = eval_epoch(model, val_loader_2, criterion)\n",
    "                history.append((train_loss, train_acc, val_loss_1, val_acc_1, val_loss_2, val_acc_2))\n",
    "                val_acc = (val_acc_1 + val_acc_2)/2\n",
    "                prev_val = val_acc_1\n",
    "                print('accuracy on 1:', val_acc_1)\n",
    "                print('accuracy on 2:', val_acc_2)\n",
    "                print('total_accuracy:', val_acc)\n",
    "                \n",
    "                \n",
    "                \n",
    "                if val_acc > best_acc and prev_val - val_acc_2 < 0.02:\n",
    "                    best_acc = val_acc\n",
    "                    best_model_weights = model.state_dict()      \n",
    "                \n",
    "                tqdm.write(\"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
    "                            val_loss_1 {v_loss:0.4f} val_loss2 {v_loss2:0.4} train_acc {t_acc:0.4f} \\\n",
    "                            val_acc_1 {v_acc:0.4f} val_acc_2 {v_acc2:0.4f}\".format(ep=epoch+1, t_loss=train_loss,\n",
    "                                           v_loss=val_loss_1, v_loss2=val_loss_2, t_acc=train_acc, v_acc=val_acc_1, v_acc2=val_acc_2))\n",
    "\n",
    "            elif number == 3:\n",
    "                val_loss_1, val_acc_1 = eval_epoch(model, val_loader_1, criterion)\n",
    "                val_loss_2, val_acc_2 = eval_epoch(model, val_loader_2, criterion)\n",
    "                val_loss_3, val_acc_3 = eval_epoch(model, val_loader_3, criterion)\n",
    "                history.append((train_loss, train_acc, val_loss_1, val_acc_1, val_loss_2, val_acc_2, val_loss_3, val_acc_3))\n",
    "                print('accuracy on 1:', val_acc_1)\n",
    "                print('accuracy on 2:', val_acc_2)\n",
    "                print('accuracy on 3:', val_acc_3)\n",
    "                val_acc = (val_acc_1 + val_acc_2 + val_acc_3)/3\n",
    "                prev_val = (val_acc_1 + val_acc_2)/2\n",
    "                print('prev_val_acc:', prev_val)\n",
    "                print('total_accuracy:', val_acc)\n",
    "                \n",
    "                if val_acc > best_acc and prev_val - val_acc_3 < 0.02:\n",
    "                    best_acc = val_acc\n",
    "                    best_model_weights = model.state_dict()  \n",
    "                \n",
    "                tqdm.write(\"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
    "                            val_loss_1 {v_loss:0.4f} val_loss_2 {v_loss2:0.4f} val_loss_3 {v_loss3:0.4f} \\\n",
    "                            train_acc {t_acc:0.4f} val_acc_1 {v_acc:0.4f} val_acc_2 {v_acc2:0.4f} val_acc_3 {v_acc3:0.4f}\\\n",
    "                            \".format(ep=epoch+1, t_loss=train_loss,\n",
    "                                           v_loss=val_loss_1, v_loss2=val_loss_2, v_loss3=val_loss_3,\n",
    "                                      t_acc=train_acc, v_acc=val_acc_1, v_acc2=val_acc_2, v_acc3=val_acc_3))  \n",
    "                      \n",
    "            elif number == 4:\n",
    "                val_loss_1, val_acc_1 = eval_epoch(model, val_loader_1, criterion)\n",
    "                val_loss_2, val_acc_2 = eval_epoch(model, val_loader_2, criterion)\n",
    "                val_loss_3, val_acc_3 = eval_epoch(model, val_loader_3, criterion)\n",
    "                val_loss_4, val_acc_4 = eval_epoch(model, val_loader_4, criterion)\n",
    "                history.append((train_loss, train_acc, val_loss_1, val_acc_1, val_loss_2, val_acc_2, val_loss_3, val_acc_3, val_loss_4, val_acc_4))\n",
    "                print('accuracy on 1:', val_acc_1)\n",
    "                print('accuracy on 2:', val_acc_2)\n",
    "                print('accuracy on 3:', val_acc_3)\n",
    "                print('accuracy on 4:', val_acc_4)\n",
    "                val_acc = (val_acc_1 + val_acc_2 + val_acc_3 + val_acc_4)/4\n",
    "                prev_val = (val_acc_1 + val_acc_2 + val_acc_3)/3\n",
    "\n",
    "                print('prev_val_acc:', prev_val)\n",
    "                print('total_accuracy:', val_acc)\n",
    "                \n",
    "                if val_acc > best_acc and prev_val - val_acc_4 < 0.02:\n",
    "                    best_acc = val_acc\n",
    "                    best_model_weights = model.state_dict()  \n",
    "                tqdm.write(\"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
    "                            val_loss_1 {v_loss:0.4f} val_loss_2 {v_loss2:0.4f} val_loss_3 {v_loss3:0.4f} val_loss_4 {v_loss4:0.4f} \\\n",
    "                            train_acc {t_acc:0.4f} val_acc_1 {v_acc:0.4f} val_acc_2 {v_acc2:0.4f} val_acc_3 {v_acc3:0.4f} val_acc_4 {v_acc4:0.4f}\\\n",
    "                            \".format(ep=epoch+1, t_loss=train_loss,\n",
    "                                           v_loss=val_loss_1, v_loss2=val_loss_2, v_loss3=val_loss_3, v_loss4=val_loss_4,\n",
    "                                      t_acc=train_acc, v_acc=val_acc_1, v_acc2=val_acc_2, v_acc3=val_acc_3, v_acc4=val_acc_4))  \n",
    "              \n",
    "            elif number == 5:\n",
    "                val_loss_1, val_acc_1 = eval_epoch(model, val_loader_1, criterion)\n",
    "                val_loss_2, val_acc_2 = eval_epoch(model, val_loader_2, criterion)\n",
    "                val_loss_3, val_acc_3 = eval_epoch(model, val_loader_3, criterion)\n",
    "                val_loss_4, val_acc_4 = eval_epoch(model, val_loader_4, criterion)\n",
    "                val_loss_5, val_acc_5 = eval_epoch(model, val_loader_5, criterion)\n",
    "\n",
    "                history.append((train_loss, train_acc, val_loss_1, val_acc_1, val_loss_2, val_acc_2, val_loss_3, val_acc_3, val_loss_4, val_acc_4, val_loss_5, val_acc_5))\n",
    "                print('accuracy on 1:', val_acc_1)\n",
    "                print('accuracy on 2:', val_acc_2)\n",
    "                print('accuracy on 3:', val_acc_3)\n",
    "                print('accuracy on 4:', val_acc_4)\n",
    "                print('accuracy on 5:', val_acc_5)\n",
    "                prev_val = (val_acc_1 + val_acc_2 + val_acc_3 + val_acc_4)/4\n",
    "                val_acc = (val_acc_1 + val_acc_2 + val_acc_3 + val_acc_4 + val_acc_5) / 5\n",
    "                print('prev_val_acc:', prev_val)\n",
    "                print('total_accuracy:', val_acc)\n",
    "                \n",
    "                if val_acc > best_acc and prev_val - val_acc_5 < 0.02:\n",
    "                    best_acc = val_acc\n",
    "                    best_model_weights = model.state_dict()  \n",
    "                \n",
    "                tqdm.write(\"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
    "                            val_loss_1 {v_loss:0.4f} val_loss_2 {v_loss2:0.4f} val_loss_3 {v_loss3:0.4f} val_loss_4 {v_loss4:0.4f} val_loss_5 {v_loss5:0.4f}\\\n",
    "                            train_acc {t_acc:0.4f} val_acc_1 {v_acc:0.4f} val_acc_2 {v_acc2:0.4f} val_acc_3 {v_acc3:0.4f} val_acc_4 {v_acc4:0.4f} val_acc_5 {v_acc5:0.4f}\\\n",
    "                            \".format(ep=epoch+1, t_loss=train_loss,\n",
    "                                           v_loss=val_loss_1, v_loss2=val_loss_2, v_loss3=val_loss_3, v_loss4=val_loss_4, v_loss5=val_loss_5,\n",
    "                                      t_acc=train_acc, v_acc=val_acc_1, v_acc2=val_acc_2, v_acc3=val_acc_3, v_acc4=val_acc_4, v_acc5=val_acc_5))  \n",
    "            #добавим сохранение лучшей модели\n",
    "\n",
    "    print('Best total accuracy:', best_acc)\n",
    "    model.load_state_dict(best_model_weights) #загрузим лучшую модель\n",
    "    return history   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:21:04.039744Z",
     "iopub.status.busy": "2022-03-27T11:21:04.039405Z",
     "iopub.status.idle": "2022-03-27T11:23:45.007014Z",
     "shell.execute_reply": "2022-03-27T11:23:45.003773Z",
     "shell.execute_reply.started": "2022-03-27T11:21:04.039694Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = train(train_dataset_1, efficient_net, 20, 1, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:23:45.009923Z",
     "iopub.status.busy": "2022-03-27T11:23:45.00962Z",
     "iopub.status.idle": "2022-03-27T11:23:45.017458Z",
     "shell.execute_reply": "2022-03-27T11:23:45.016314Z",
     "shell.execute_reply.started": "2022-03-27T11:23:45.00989Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_part_files(tr_files):\n",
    "    tr_files_1 = np.array(tr_files)\n",
    "    tr_files_1 = tr_files_1[np.random.permutation(len(tr_files_1))[:len(tr_files_1)//5]]\n",
    "    tr_files_1 = np.repeat(tr_files_1, 5)\n",
    "    tr_files_1 = tr_files_1[np.random.permutation(len(tr_files_1))]\n",
    "    return list(tr_files_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:23:45.019397Z",
     "iopub.status.busy": "2022-03-27T11:23:45.01907Z",
     "iopub.status.idle": "2022-03-27T11:23:45.034861Z",
     "shell.execute_reply": "2022-03-27T11:23:45.033799Z",
     "shell.execute_reply.started": "2022-03-27T11:23:45.019351Z"
    }
   },
   "outputs": [],
   "source": [
    "new_tr_files_1 = get_part_files(train_files_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:23:59.699674Z",
     "iopub.status.busy": "2022-03-27T11:23:59.69927Z",
     "iopub.status.idle": "2022-03-27T11:23:59.708169Z",
     "shell.execute_reply": "2022-03-27T11:23:59.706811Z",
     "shell.execute_reply.started": "2022-03-27T11:23:59.699617Z"
    }
   },
   "outputs": [],
   "source": [
    "len(new_tr_files_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:24:00.063252Z",
     "iopub.status.busy": "2022-03-27T11:24:00.062294Z",
     "iopub.status.idle": "2022-03-27T11:24:00.113762Z",
     "shell.execute_reply": "2022-03-27T11:24:00.112804Z",
     "shell.execute_reply.started": "2022-03-27T11:24:00.063168Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_clf_2 = ImageNetteDataset(train_files_2 + new_tr_files_1, mode='train', part=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:24:01.031901Z",
     "iopub.status.busy": "2022-03-27T11:24:01.03109Z",
     "iopub.status.idle": "2022-03-27T11:24:01.897199Z",
     "shell.execute_reply": "2022-03-27T11:24:01.895962Z",
     "shell.execute_reply.started": "2022-03-27T11:24:01.031852Z"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:24:01.900594Z",
     "iopub.status.busy": "2022-03-27T11:24:01.899822Z",
     "iopub.status.idle": "2022-03-27T11:24:01.907572Z",
     "shell.execute_reply": "2022-03-27T11:24:01.906388Z",
     "shell.execute_reply.started": "2022-03-27T11:24:01.900541Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(train_dataset_clf_2))\n",
    "#print(len(train_dataset_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:24:09.573669Z",
     "iopub.status.busy": "2022-03-27T11:24:09.573231Z",
     "iopub.status.idle": "2022-03-27T11:27:34.548488Z",
     "shell.execute_reply": "2022-03-27T11:27:34.547258Z",
     "shell.execute_reply.started": "2022-03-27T11:24:09.573616Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = new_ewc_train(train_dataset_clf_2, train_dataset_1, efficient_net, epochs=10, number=2, batch_size=64, importance=4e12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:27:34.55283Z",
     "iopub.status.busy": "2022-03-27T11:27:34.552479Z",
     "iopub.status.idle": "2022-03-27T11:27:35.416467Z",
     "shell.execute_reply": "2022-03-27T11:27:35.41531Z",
     "shell.execute_reply.started": "2022-03-27T11:27:34.55279Z"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:27:35.421372Z",
     "iopub.status.busy": "2022-03-27T11:27:35.421067Z",
     "iopub.status.idle": "2022-03-27T11:27:35.434501Z",
     "shell.execute_reply": "2022-03-27T11:27:35.433439Z",
     "shell.execute_reply.started": "2022-03-27T11:27:35.421336Z"
    }
   },
   "outputs": [],
   "source": [
    "new_tr_files_2 = get_part_files(train_files_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:27:35.439029Z",
     "iopub.status.busy": "2022-03-27T11:27:35.438564Z",
     "iopub.status.idle": "2022-03-27T11:27:35.515537Z",
     "shell.execute_reply": "2022-03-27T11:27:35.514396Z",
     "shell.execute_reply.started": "2022-03-27T11:27:35.43891Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_dataset_clf_3 = ImageNetteDataset(train_files_3 + new_tr_files_2 + new_tr_files_1, mode='train', part=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:27:35.517704Z",
     "iopub.status.busy": "2022-03-27T11:27:35.516974Z",
     "iopub.status.idle": "2022-03-27T11:27:36.394008Z",
     "shell.execute_reply": "2022-03-27T11:27:36.392727Z",
     "shell.execute_reply.started": "2022-03-27T11:27:35.517613Z"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:27:36.398366Z",
     "iopub.status.busy": "2022-03-27T11:27:36.397089Z",
     "iopub.status.idle": "2022-03-27T11:35:27.582791Z",
     "shell.execute_reply": "2022-03-27T11:35:27.581531Z",
     "shell.execute_reply.started": "2022-03-27T11:27:36.398315Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = new_ewc_train(train_dataset_clf_3, train_dataset_clf_2, efficient_net, epochs=15, number=3, batch_size=64, importance=5e9) # добавить точность на конкретных классах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:35:27.586218Z",
     "iopub.status.busy": "2022-03-27T11:35:27.585266Z",
     "iopub.status.idle": "2022-03-27T11:35:27.8256Z",
     "shell.execute_reply": "2022-03-27T11:35:27.824361Z",
     "shell.execute_reply.started": "2022-03-27T11:35:27.586159Z"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:35:27.8284Z",
     "iopub.status.busy": "2022-03-27T11:35:27.827554Z",
     "iopub.status.idle": "2022-03-27T11:35:28.699723Z",
     "shell.execute_reply": "2022-03-27T11:35:28.69834Z",
     "shell.execute_reply.started": "2022-03-27T11:35:27.828336Z"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:35:28.704038Z",
     "iopub.status.busy": "2022-03-27T11:35:28.702248Z",
     "iopub.status.idle": "2022-03-27T11:35:29.772397Z",
     "shell.execute_reply": "2022-03-27T11:35:29.771182Z",
     "shell.execute_reply.started": "2022-03-27T11:35:28.703968Z"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:35:29.777952Z",
     "iopub.status.busy": "2022-03-27T11:35:29.777628Z",
     "iopub.status.idle": "2022-03-27T11:35:29.790265Z",
     "shell.execute_reply": "2022-03-27T11:35:29.787197Z",
     "shell.execute_reply.started": "2022-03-27T11:35:29.777917Z"
    }
   },
   "outputs": [],
   "source": [
    "new_tr_files_3 = get_part_files(train_files_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:35:29.792782Z",
     "iopub.status.busy": "2022-03-27T11:35:29.791725Z",
     "iopub.status.idle": "2022-03-27T11:35:29.890638Z",
     "shell.execute_reply": "2022-03-27T11:35:29.889638Z",
     "shell.execute_reply.started": "2022-03-27T11:35:29.792733Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_dataset_clf_4 = ImageNetteDataset(train_files_4 + new_tr_files_3 + new_tr_files_2 + new_tr_files_1, mode='train', part=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:35:29.892841Z",
     "iopub.status.busy": "2022-03-27T11:35:29.892442Z",
     "iopub.status.idle": "2022-03-27T11:42:47.556341Z",
     "shell.execute_reply": "2022-03-27T11:42:47.555128Z",
     "shell.execute_reply.started": "2022-03-27T11:35:29.892795Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = new_ewc_train(train_dataset_clf_4, train_dataset_clf_3, efficient_net, epochs=10, number=4, batch_size=64, importance=5e9) # добавить точность на конкретных классах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:42:47.559158Z",
     "iopub.status.busy": "2022-03-27T11:42:47.558776Z",
     "iopub.status.idle": "2022-03-27T11:42:48.664164Z",
     "shell.execute_reply": "2022-03-27T11:42:48.662888Z",
     "shell.execute_reply.started": "2022-03-27T11:42:47.559101Z"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:42:48.668064Z",
     "iopub.status.busy": "2022-03-27T11:42:48.667491Z",
     "iopub.status.idle": "2022-03-27T11:42:48.679056Z",
     "shell.execute_reply": "2022-03-27T11:42:48.677661Z",
     "shell.execute_reply.started": "2022-03-27T11:42:48.668012Z"
    }
   },
   "outputs": [],
   "source": [
    "new_tr_files_4 = get_part_files(train_files_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:42:48.681448Z",
     "iopub.status.busy": "2022-03-27T11:42:48.681085Z",
     "iopub.status.idle": "2022-03-27T11:42:48.802459Z",
     "shell.execute_reply": "2022-03-27T11:42:48.801335Z",
     "shell.execute_reply.started": "2022-03-27T11:42:48.681401Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_dataset_clf_5 = ImageNetteDataset(train_files_5 + new_tr_files_4 + new_tr_files_3 + new_tr_files_2 + new_tr_files_1, mode='train', part=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T11:42:48.804648Z",
     "iopub.status.busy": "2022-03-27T11:42:48.8043Z",
     "iopub.status.idle": "2022-03-27T11:56:53.227245Z",
     "shell.execute_reply": "2022-03-27T11:56:53.226162Z",
     "shell.execute_reply.started": "2022-03-27T11:42:48.804601Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = new_ewc_train(train_dataset_clf_5, train_dataset_clf_4, efficient_net, epochs=15, number=5, batch_size=64, importance=4e9) # добавить точность на конкретных классах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
