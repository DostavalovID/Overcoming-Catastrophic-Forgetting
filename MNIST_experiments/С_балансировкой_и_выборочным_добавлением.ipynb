{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "С балансировкой и выборочным добавлением.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPumWBJ5wpan"
      },
      "source": [
        "from six.moves import urllib\n",
        "opener = urllib.request.build_opener()\n",
        "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
        "urllib.request.install_opener(opener)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3yY-a4IwxG6"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from copy import deepcopy\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F \n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0) \n",
        "#torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSNwelkFwxPj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "11022cc9-5a31-4f88-a125-a5668c53024e"
      },
      "source": [
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "MNIST_train = MNIST('./', download=True, transform = transforms.ToTensor(), train=True)\n",
        "MNIST_test = MNIST('./', download=True, transform = transforms.ToTensor(), train=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b6baa5ccb534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mMNIST_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mMNIST_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresources\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mdownload_and_extract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;31m# process and save as torch files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0m_urlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;31m# check integrity of downloaded file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloading '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0m_urlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'https'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_urlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUSER_AGENT\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 503: Service Unavailable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnyXfRBewxWe"
      },
      "source": [
        "#import matplotlib.pyplot as plt\n",
        "#for i in range(5):\n",
        "#  plt.imshow(X_train_01[i,:,:])\n",
        "#  plt.show()\n",
        "#  print(y_train_01[i])\n",
        "#for i in range(5):\n",
        "#  plt.imshow(X_train_23[i,:,:])\n",
        "#  plt.show()\n",
        "#  print(y_train_23[i])\n",
        "#for i in range(5):\n",
        "#  plt.imshow(X_train_45[i,:,:])\n",
        "#  plt.show()\n",
        "#  print(y_train_45[i])\n",
        "#for i in range(5):\n",
        "#  plt.imshow(X_train_67[i,:,:])\n",
        "#  plt.show()\n",
        "#  print(y_train_67[i])\n",
        "#for i in range(5):\n",
        "#  plt.imshow(X_train_89[i,:,:])\n",
        "#  plt.show()\n",
        "#  print(y_train_89[i])\n",
        "\n",
        "\n",
        "\n",
        "X_train = MNIST_train.data\n",
        "y_train = MNIST_train.targets\n",
        "X_test = MNIST_test.data\n",
        "y_test = MNIST_test.targets\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_indices_01 = []\n",
        "train_indices_23 = []\n",
        "train_indices_45 = []\n",
        "train_indices_67 = []\n",
        "train_indices_89 = []\n",
        "test_indices_01 = []\n",
        "test_indices_23 = []\n",
        "test_indices_45 = []\n",
        "test_indices_67 = []\n",
        "test_indices_89 = []\n",
        "for i in range(len(y_train)):\n",
        "  if y_train[i] == 0 or y_train[i] == 1:\n",
        "    train_indices_01.append(i)\n",
        "  elif y_train[i] == 2 or y_train[i] == 3:\n",
        "    train_indices_23.append(i)\n",
        "  elif y_train[i] == 4 or y_train[i] == 5:\n",
        "    train_indices_45.append(i)\n",
        "  elif y_train[i] == 6 or y_train[i] == 7:\n",
        "    train_indices_67.append(i)\n",
        "  elif y_train[i] == 8 or y_train[i] == 9:\n",
        "    train_indices_89.append(i)\n",
        "  \n",
        "\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  if y_test[i] == 0 or y_test[i] == 1:\n",
        "    test_indices_01.append(i)\n",
        "  elif y_test[i] == 2 or y_test[i]== 3:\n",
        "    test_indices_23.append(i)\n",
        "  elif y_test[i] == 4 or y_test[i] == 5:\n",
        "    test_indices_45.append(i)\n",
        "  elif y_test[i] == 6 or y_test[i] == 7:\n",
        "    test_indices_67.append(i)\n",
        "  elif y_test[i] == 8 or y_test[i] == 9:\n",
        "    test_indices_89.append(i)\n",
        "\n",
        "\n",
        "\n",
        "X_train_01 = X_train[train_indices_01]\n",
        "y_train_01 = y_train[train_indices_01]\n",
        "X_test_01 = X_test[test_indices_01]\n",
        "y_test_01 = y_test[test_indices_01]\n",
        "\n",
        "X_train_23 = X_train[train_indices_23]\n",
        "y_train_23 = y_train[train_indices_23]\n",
        "X_test_23 = X_test[test_indices_23]\n",
        "y_test_23 = y_test[test_indices_23]\n",
        "\n",
        "X_train_45 = X_train[train_indices_45]\n",
        "y_train_45 = y_train[train_indices_45]\n",
        "X_test_45 = X_test[test_indices_45]\n",
        "y_test_45 = y_test[test_indices_45]\n",
        "\n",
        "X_train_67 = X_train[train_indices_67]\n",
        "y_train_67 = y_train[train_indices_67]\n",
        "X_test_67 = X_test[test_indices_67]\n",
        "y_test_67 = y_test[test_indices_67]\n",
        "\n",
        "X_train_89 = X_train[train_indices_89]\n",
        "y_train_89 = y_train[train_indices_89]\n",
        "X_test_89 = X_test[test_indices_89]\n",
        "y_test_89 = y_test[test_indices_89]\n",
        "\n",
        "\n",
        "X_test_01 = X_test_01.to(device)\n",
        "print(type(y_train_01))\n",
        "print(y_train_01[0])\n",
        "\n",
        "\n",
        "X_train = X_train.unsqueeze(1).float()\n",
        "X_test = X_test.unsqueeze(1).float()\n",
        "\n",
        "X_train_01 = X_train_01.unsqueeze(1).float()\n",
        "X_test_01 = X_test_01.unsqueeze(1).float()\n",
        "\n",
        "X_train_23 = X_train_23.unsqueeze(1).float()\n",
        "X_test_23 = X_test_23.unsqueeze(1).float()\n",
        "\n",
        "X_train_45 = X_train_45.unsqueeze(1).float()\n",
        "X_test_45 = X_test_45.unsqueeze(1).float()\n",
        "\n",
        "X_train_67 = X_train_67.unsqueeze(1).float()\n",
        "X_test_67 = X_test_67.unsqueeze(1).float()\n",
        "\n",
        "X_train_89 = X_train_89.unsqueeze(1).float()\n",
        "X_test_89 = X_test_89.unsqueeze(1).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoH_ZCNIwxek"
      },
      "source": [
        "class YannLecun(torch.nn.Module):\n",
        "  def __init__(self,activation = 'leaky relu', pooling = 'max', conv_size = 3, use_batch_norm = False, use_dropout = False):\n",
        "    super(YannLecun, self).__init__()\n",
        "    self.conv_size = conv_size\n",
        "    self.use_batch_norm = use_batch_norm\n",
        "    self.use_dropout = use_dropout\n",
        "\n",
        "    if activation == 'relu':\n",
        "      activation_function = torch.nn.ReLU()\n",
        "    elif activation == 'tanh':\n",
        "      activation_function = torch.nn.Tanh()\n",
        "    elif activation == 'leaky relu':\n",
        "        activation_function = torch.nn.LeakyReLU()\n",
        "    else:\n",
        "      raise NotImplementedError   \n",
        "\n",
        "    if pooling == 'max':\n",
        "      pooling_layer = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    elif pooling == 'avg':\n",
        "      pooling_layer = torch.nn.AvgPool2d(kernel_size = 2, stride = 2)\n",
        "    else:\n",
        "      raise NotImplementedError   \n",
        "    \n",
        "    if conv_size == 3:\n",
        "      self.conv1_1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, padding= 1)\n",
        "      self.conv1_2 = torch.nn.Conv2d(in_channels=6, out_channels=6, kernel_size=3, padding= 1)\n",
        "    elif conv_size == 5:\n",
        "      self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding= 2)\n",
        "    else:\n",
        "      raise NotImplementedError\n",
        "    \n",
        "    self.act1 = activation_function\n",
        "    self.bn1 = torch.nn.BatchNorm2d(num_features = 6)\n",
        "    self.pool1 = pooling_layer\n",
        "    self.dp1 = torch.nn.Dropout(p = 0.25) \n",
        "\n",
        "    if conv_size == 3:\n",
        "      self.conv2_1 = torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, padding= 0)\n",
        "      self.conv2_2 = torch.nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding= 0)\n",
        "    elif conv_size == 5:\n",
        "      self.conv2 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding= 0)\n",
        "    else:\n",
        "      raise NotImplementedError\n",
        "\n",
        "    self.act2 = activation_function\n",
        "    self.bn2 = torch.nn.BatchNorm2d(num_features = 16)\n",
        "    self.pool2 = pooling_layer\n",
        "    self.dp2 = torch.nn.Dropout(p = 0.25) \n",
        "\n",
        "    self.fc1 = torch.nn.Linear(5*5*16, 120)\n",
        "    self.act3 = torch.nn.Tanh()\n",
        "    self.dp3 = torch.nn.Dropout(p = 0.5) \n",
        "\n",
        "    self.fc2 = torch.nn.Linear(120,84)\n",
        "    self.act4 = torch.nn.Tanh()\n",
        "    self.dp4 = torch.nn.Dropout(p = 0.5) \n",
        "\n",
        "    self.fc3 = torch.nn.Linear(84,10)\n",
        "    self.act5 = torch.nn.Softmax()\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    if self.conv_size == 3:\n",
        "      x = self.conv1_1(x)\n",
        "      x = self.conv1_2(x)\n",
        "    elif self.conv_size == 5:\n",
        "      x = self.conv1(x)\n",
        "\n",
        "    x = self.act1(x)\n",
        "    if self.use_batch_norm:\n",
        "      x = self.bn1(x)\n",
        "    x = self.pool1(x)\n",
        "    if self.use_dropout:\n",
        "      x = self.dp1(x)\n",
        "\n",
        "\n",
        "    if self.conv_size == 3:\n",
        "      x = self.conv2_1(x)\n",
        "      x = self.conv2_2(x)\n",
        "    elif self.conv_size == 5:\n",
        "      x = self.conv2(x)\n",
        "    \n",
        "    x = self.act2(x)\n",
        "    if self.use_batch_norm:\n",
        "      x = self.bn2(x)\n",
        "    x = self.pool2(x)\n",
        "    if self.use_dropout:\n",
        "      x = self.dp2(x)\n",
        "\n",
        "    x = x.view(x.size(0),x.size(1)*x.size(2)*x.size(3))\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = self.act3(x)\n",
        "    if self.use_dropout:\n",
        "      x = self.dp3(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.act4(x)\n",
        "    if self.use_dropout:\n",
        "      x = self.dp4(x)\n",
        "    x = self.fc3(x)\n",
        "    x = self.act5(x)\n",
        "    \n",
        "    x = x.to(device)\n",
        "\n",
        "    return x\n",
        "\n",
        "yann_lecun = YannLecun(use_batch_norm = True, use_dropout =True)\n",
        "yann_lecun = yann_lecun.to(device)\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "my_optimizer = torch.optim.Adam(yann_lecun.parameters(), lr=4.0e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLwL0Y4mwxl4"
      },
      "source": [
        "def variable(t: torch.Tensor, use_cuda=True, **kwargs): #переменная тупо для того, чтобы можно было дифференцировать по ним.\n",
        "    if torch.cuda.is_available() and use_cuda:          #в нашем случае в самом тензоре есть requires_grad если True то переменная\n",
        "        t = t.cuda()\n",
        "    return Variable(t, **kwargs)\n",
        "\n",
        "\n",
        "class EWC(object):\n",
        "    def __init__(self, old_x, old_y = None, model = yann_lecun):\n",
        "\n",
        "        self.model = model\n",
        "        self.old_x = old_x # по сути иксы\n",
        "        self.old_y = old_y\n",
        "        self.params = {n: p for n, p in self.model.named_parameters() if p.requires_grad} #собирает в словарь имя:параметры\n",
        "        self._old_params = {}\n",
        "        self._precision_matrices = self._diag_fisher() \n",
        "\n",
        "        for n, p in deepcopy(self.params).items():\n",
        "            self._old_params[n] = variable(p.data)\n",
        "\n",
        "\n",
        "    def _diag_fisher(self):\n",
        "        precision_matrices = {}\n",
        "        for n, p in deepcopy(self.params).items(): #копируем параметры через дип копи чтоб не поменять их\n",
        "            p.data.zero_() #все параметры скопированные зануляем\n",
        "            precision_matrices[n] = variable(p.data) #выставляем requires_grad = True \n",
        "\n",
        "        self.model.eval() #переводим в состояние evaluation\n",
        "        #for input in self.dataset:\n",
        "        self.model.zero_grad() #как обычно чтоб не накапливался градиент зануляем вначале\n",
        "        self.old_x = variable(self.old_x) #input requires grad = True\n",
        "        output = self.model(self.old_x)#.view(1, -1)\n",
        "        output = output.to(device)\n",
        "        loss = F.nll_loss(F.log_softmax(output, dim=1), self.old_y)\n",
        "        loss.backward()\n",
        "\n",
        "        for n, p in self.model.named_parameters():\n",
        "            #print(f\"p grad data shape = {p.grad.data.shape}\")\n",
        "            precision_matrices[n].data += p.grad.data ** 2 / len(self.old_x) #то, чточ делим на число это типа матожидание берем\n",
        "\n",
        "        precision_matrices = {n: p for n, p in precision_matrices.items()}\n",
        "        return precision_matrices\n",
        "\n",
        "    def penalty(self, model: nn.Module):\n",
        "        loss = 0\n",
        "        for n, p in model.named_parameters():\n",
        "            _loss = self._precision_matrices[n].data * (p - self._old_params[n].data) ** 2\n",
        "            loss += _loss.sum()\n",
        "        return loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoM8ITwlwxtc"
      },
      "source": [
        "def normal_train(X_trains, y_trains, X_tests, y_tests, model = yann_lecun, optimizer = my_optimizer, epochs = 5, batch_sizes = 100):\n",
        "    model.train() #выставляем, что она меняет свои коэф\n",
        "    batch_size = batch_sizes\n",
        "    test_accuracy_history = []\n",
        "    test_loss_history = []\n",
        "\n",
        "    X_tests = X_tests.to(device)\n",
        "    y_tests = y_tests.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        order = np.random.permutation(len(X_trains))\n",
        "        for start_index in range(0,len(X_trains), batch_size):\n",
        "            batch_indexes = order[start_index:start_index+batch_size]\n",
        "\n",
        "            X_batch = X_trains[batch_indexes].to(device)\n",
        "            y_batch = y_trains[batch_indexes].to(device)\n",
        "\n",
        "            X_batch, y_batch = variable(X_batch), variable(y_batch)\n",
        "            optimizer.zero_grad()\n",
        "            preds = model.forward(X_batch)\n",
        "            loss_value = loss(preds, y_batch)\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        test_preds = model.forward(X_tests)\n",
        "        test_loss_history.append(loss(test_preds, y_tests).data.cpu())\n",
        "\n",
        "        accuracy = (test_preds.argmax(dim = 1) == y_tests).float().mean().data.cpu()\n",
        "        test_accuracy_history.append(accuracy)\n",
        "        print(accuracy)  \n",
        "\n",
        "\n",
        "def ewc_train(X_trains, y_trains, X_tests, y_tests, old_x_test, old_y_test, number, \n",
        "              ewc: EWC, importance, epochs = 0, model = yann_lecun, optimizer = my_optimizer, batch_sizes = 100):\n",
        "    model.train() #выставляем, что она меняет свои коэф\n",
        "    #epoch_loss = 0\n",
        "    batch_size = batch_sizes\n",
        "    test_accuracy_history = []\n",
        "    test_loss_history = []\n",
        "\n",
        "    X_tests = X_tests.to(device)\n",
        "    y_tests = y_tests.to(device)\n",
        "    temp_epoch = 1\n",
        "    while True:\n",
        "        order = np.random.permutation(len(X_trains))\n",
        "        for start_index in range(0,len(X_trains), batch_size):\n",
        "            batch_indexes = order[start_index:start_index+batch_size]\n",
        "\n",
        "            X_batch = X_trains[batch_indexes].to(device)\n",
        "            y_batch = y_trains[batch_indexes].to(device)\n",
        "\n",
        "            X_batch, y_batch = variable(X_batch), variable(y_batch)\n",
        "            optimizer.zero_grad()\n",
        "            preds = model.forward(X_batch)\n",
        "            loss_value = loss(preds, y_batch) + importance * ewc.penalty(model)\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        test_preds = model.forward(X_tests)\n",
        "        test_loss_history.append(loss(test_preds, y_tests).data.cpu())\n",
        "\n",
        "        accuracy = (test_preds.argmax(dim = 1) == y_tests).float().mean().data.cpu()\n",
        "        test_accuracy_history.append(accuracy)\n",
        "        old_accuracy = test_accuracy(old_x_test, old_y_test)\n",
        "        print('accuracy on current task: ',accuracy)\n",
        "        print('accuracy on old task: ', old_accuracy)\n",
        "        if number == 1:\n",
        "            print('accuracy on 01: ', test_accuracy(X_test_01,y_test_01),'\\n')\n",
        "        elif number == 2:\n",
        "            print('accuracy on 01: ', test_accuracy(X_test_01,y_test_01))\n",
        "            print('accuracy on 23: ', test_accuracy(X_test_23,y_test_23),'\\n')\n",
        "        elif number == 3:\n",
        "            print('accuracy on 01: ', test_accuracy(X_test_01,y_test_01))\n",
        "            print('accuracy on 23: ', test_accuracy(X_test_23,y_test_23))\n",
        "            print('accuracy on 45: ', test_accuracy(X_test_45,y_test_45),'\\n')\n",
        "        elif number == 4:\n",
        "            print('accuracy on 01: ', test_accuracy(X_test_01,y_test_01))\n",
        "            print('accuracy on 23: ', test_accuracy(X_test_23,y_test_23))\n",
        "            print('accuracy on 45: ', test_accuracy(X_test_45,y_test_45))\n",
        "            print('accuracy on 67: ', test_accuracy(X_test_67,y_test_67),'\\n')\n",
        "\n",
        "        if temp_epoch == epochs:\n",
        "            break\n",
        "        temp_epoch += 1\n",
        "        if (accuracy >= old_accuracy or (abs(accuracy - old_accuracy) <= 0.05 and number == 1) or abs(accuracy - old_accuracy) <= 0.03) and epochs == 0:\n",
        "            break\n",
        "\n",
        "def test_accuracy(x_test, y_test):\n",
        "    x_test = x_test.to(device)\n",
        "    test_preds = yann_lecun.forward(x_test)\n",
        "    test_preds = test_preds.to(device)\n",
        "    y_test = y_test.to(device)\n",
        "    accuracy = (test_preds.argmax(dim = 1) == y_test).float().mean().data.cpu()\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def get_indices(x_train, percentage):\n",
        "    order = np.random.permutation(len(x_train))\n",
        "    print('order type is ', type(order))\n",
        "    return order[:(len(order)*percentage)//100]\n",
        "\n",
        "def get_worst_ind(model, x_train, y_train, percentage):\n",
        "    preds = model.forward(x_train.to(device))\n",
        "    enough = (len(preds)*percentage)//100\n",
        "    worst_inds = []\n",
        "    for i in range(len(preds)):\n",
        "        if preds[i].argmax() != y_train[i]:\n",
        "            worst_inds.append(i)\n",
        "    already_have = len(worst_inds)\n",
        "    if already_have >= enough:\n",
        "        return np.array(worst_inds[:enough])\n",
        "    set_worst_inds = set(worst_inds)\n",
        "    print(set_worst_inds)\n",
        "    for i in np.random.permutation(len(x_train)):\n",
        "        if already_have == enough: return np.array(worst_inds)\n",
        "        if i not in set_worst_inds:\n",
        "            worst_inds.append(i)\n",
        "            already_have += 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68v1-Bupwx0p"
      },
      "source": [
        "pytorch_total_params = sum(p.numel() for p in yann_lecun.parameters())\n",
        "print(pytorch_total_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHBr1Deowx8A"
      },
      "source": [
        "normal_train(X_train_01,y_train_01,X_test_01,y_test_01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUqmFBMkwyDa"
      },
      "source": [
        "\n",
        "old_tasks = X_train_01\n",
        "old_y = y_train_01\n",
        "old_x_test = X_test_01\n",
        "old_y_test = y_test_01\n",
        "\n",
        "order = get_worst_ind(yann_lecun, X_train_01, y_train_01, 20)\n",
        "\n",
        "\n",
        "cur_x_train = torch.cat((X_train_23, X_train_01[order]))\n",
        "cur_y_train = torch.cat((y_train_23.to(device), y_train_01[order].to(device)))\n",
        "new_permutation = np.random.permutation(len(cur_x_train))\n",
        "cur_x_train = cur_x_train[new_permutation]\n",
        "cur_y_train = cur_y_train[new_permutation]\n",
        "\n",
        "old_y = old_y.to(device)\n",
        "my_ewc = EWC(old_tasks, old_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTuYA1HHwyKd"
      },
      "source": [
        "ewc_train(cur_x_train,cur_y_train,X_test_23,y_test_23,old_x_test, old_y_test,1, my_ewc, importance = 0.4e15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzEo0dzgxF4F"
      },
      "source": [
        "#ewc_train(cur_x_train,cur_y_train,X_test_23,y_test_23,old_x_test, old_y_test, 1, my_ewc, epochs = 1, importance = 1e15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWX_MHgxwyiS"
      },
      "source": [
        "print(f\"Accuracy on 01: {test_accuracy(old_x_test, old_y_test)}\")\n",
        "cur_x_test = X_test_23\n",
        "cur_x_test = cur_x_test.to(device)\n",
        "cur_y_test = y_test_23\n",
        "\n",
        "print(f\"Accuracy on 23: {test_accuracy(cur_x_test, cur_y_test)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kTFqXzHwyvY"
      },
      "source": [
        "old_tasks = torch.cat((old_tasks,X_train_23))\n",
        "old_x_test = torch.cat((old_x_test, cur_x_test))\n",
        "old_y_test = torch.cat((old_y_test,cur_y_test))\n",
        "y_train_23 = y_train_23.to(device)\n",
        "old_y = torch.cat((old_y, y_train_23))\n",
        "old_y = old_y.to(device)\n",
        "\n",
        "\n",
        "order_1 = get_worst_ind(yann_lecun, X_train_01, y_train_01, 20)\n",
        "order_2 = get_worst_ind(yann_lecun, X_train_23, y_train_23, 20)\n",
        "cur_x_train = torch.cat((X_train_45, X_train_01[order_1], X_train_23[order_2]))\n",
        "cur_y_train = torch.cat((y_train_45.to(device), y_train_01[order_1].to(device), y_train_23[order_2]))\n",
        "new_permutation = np.random.permutation(len(cur_x_train))\n",
        "cur_x_train = cur_x_train[new_permutation]\n",
        "cur_y_train = cur_y_train[new_permutation]\n",
        "my_ewc = EWC(old_tasks, old_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzHzgO00xLlq"
      },
      "source": [
        "ewc_train(cur_x_train,cur_y_train,X_test_45,y_test_45, old_x_test, old_y_test, 2, my_ewc, importance = 5e11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHvSXAQrxLwJ"
      },
      "source": [
        "#ewc_train(cur_x_train,cur_y_train,X_test_45,y_test_45, old_x_test, old_y_test, 2, my_ewc, epochs = 1, importance = 10e11)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyW3qhXVxL4B"
      },
      "source": [
        "cur_x_test = X_test_45\n",
        "cur_y_test = y_test_45\n",
        "print(f\"Accuracy on 45: {test_accuracy(cur_x_test, cur_y_test)}\")\n",
        "old_x_test = torch.cat((old_x_test,cur_x_test.to(device)))\n",
        "old_y_test = torch.cat((old_y_test,cur_y_test))\n",
        "print(f\"Accuracy on 012345: {test_accuracy(old_x_test, old_y_test)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO1z14v7xMBJ"
      },
      "source": [
        "old_tasks = torch.cat((old_tasks,X_train_45))\n",
        "y_train_45 = y_train_45.to(device)\n",
        "old_y = torch.cat((old_y, y_train_45))\n",
        "old_y = old_y.to(device)\n",
        "\n",
        "order_1 = get_worst_ind(yann_lecun, X_train_01, y_train_01, 20)\n",
        "order_2 = get_worst_ind(yann_lecun, X_train_23, y_train_23, 20)\n",
        "order_3 = get_worst_ind(yann_lecun, X_train_45, y_train_45, 20)\n",
        "\n",
        "cur_x_train = torch.cat((X_train_67, X_train_01[order_1], X_train_23[order_2], X_train_45[order_3]))\n",
        "cur_y_train = torch.cat((y_train_67.to(device), y_train_01[order_1].to(device), y_train_23[order_2].to(device), y_train_45[order_3].to(device)))\n",
        "new_permutation = np.random.permutation(len(cur_x_train))\n",
        "cur_x_train = cur_x_train[new_permutation]\n",
        "cur_y_train = cur_y_train[new_permutation]\n",
        "\n",
        "my_ewc = EWC(old_tasks, old_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM4nRU8UxMKt"
      },
      "source": [
        "ewc_train(cur_x_train,cur_y_train,X_test_67,y_test_67, old_x_test, old_y_test, 3, my_ewc, importance = 4e11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcZ2Ta4FxMT_"
      },
      "source": [
        "#ewc_train(cur_x_train,cur_y_train,X_test_67,y_test_67, old_x_test, old_y_test, 3, my_ewc, epochs = 1, importance = 6e11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj4nDJ18xTQe"
      },
      "source": [
        "    cur_x_test = X_test_67\n",
        "    cur_y_test = y_test_67\n",
        "    print(f\"Accuracy on 67: {test_accuracy(cur_x_test, cur_y_test)}\")\n",
        "\n",
        "    old_x_test = torch.cat((old_x_test,cur_x_test.to(device)))\n",
        "    old_y_test = torch.cat((old_y_test,cur_y_test))\n",
        "    print(f\"Accuracy on 01234567: {test_accuracy(old_x_test, old_y_test)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lw2gcMvxTXh"
      },
      "source": [
        "old_tasks = torch.cat((old_tasks,X_train_67))\n",
        "y_train_67 = y_train_67.to(device)\n",
        "old_y = torch.cat((old_y, y_train_67))\n",
        "old_y = old_y.to(device)\n",
        "\n",
        "order_1 = get_worst_ind(yann_lecun, X_train_01, y_train_01, 20)\n",
        "order_2 = get_worst_ind(yann_lecun, X_train_23, y_train_23, 20)\n",
        "order_3 = get_worst_ind(yann_lecun, X_train_45, y_train_45, 20)\n",
        "order_4 = get_worst_ind(yann_lecun, X_train_67, y_train_67, 20)\n",
        "\n",
        "\n",
        "cur_x_train = torch.cat((X_train_89, X_train_01[order_1], X_train_23[order_2], X_train_45[order_3], X_train_67[order_4]))\n",
        "cur_y_train = torch.cat((y_train_89.to(device), y_train_01[order_1].to(device), y_train_23[order_2].to(device), y_train_45[order_3].to(device), y_train_67[order_4].to(device)))\n",
        "new_permutation = np.random.permutation(len(cur_x_train))\n",
        "cur_x_train = cur_x_train[new_permutation]\n",
        "cur_y_train = cur_y_train[new_permutation]\n",
        "\n",
        "\n",
        "my_ewc = EWC(old_tasks, old_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax2Kc1nFxThc"
      },
      "source": [
        " ewc_train(cur_x_train,cur_y_train,X_test_89,y_test_89,old_x_test, old_y_test, 4, my_ewc, importance = 2e11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpObveE7xYTb"
      },
      "source": [
        "#ewc_train(cur_x_train,cur_y_train,X_test_89,y_test_89,old_x_test, old_y_test, 4, my_ewc, epochs = 1, importance = 12e11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLeiixjixYaH"
      },
      "source": [
        "cur_x_test = X_test_89\n",
        "cur_y_test = y_test_89\n",
        "print(f\"Accuracy on 89: {test_accuracy(cur_x_test, cur_y_test)}\")\n",
        "\n",
        "old_x_test = torch.cat((old_x_test,cur_x_test.to(device)))\n",
        "old_y_test = torch.cat((old_y_test,cur_y_test))\n",
        "print(f\"Total accuracy: {test_accuracy(old_x_test, old_y_test)}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}