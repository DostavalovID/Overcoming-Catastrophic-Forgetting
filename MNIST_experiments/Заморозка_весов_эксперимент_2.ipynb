{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Заморозка весов эксперимент 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3k4ljr-L0ML"
      },
      "source": [
        "from six.moves import urllib\n",
        "opener = urllib.request.build_opener()\n",
        "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
        "urllib.request.install_opener(opener)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWWyrIktCxME"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from copy import deepcopy\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0) \n",
        "#torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h2lU13wea1i"
      },
      "source": [
        "import torchvision.datasets\n",
        "\n",
        "MNIST_train = torchvision.datasets.MNIST('./', download=True, train = True)\n",
        "MNIST_test = torchvision.datasets.MNIST('./', download=True, train = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0Yz-YbyMA-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f2d164a-34d9-4b94-c6f3-ca5c21e03d68"
      },
      "source": [
        "#import matplotlib.pyplot as plt\n",
        "#for i in range(5):\n",
        "#  plt.imshow(X_train_01[i,:,:])\n",
        "#  plt.show()\n",
        "#  print(y_train_01[i])\n",
        "#for i in range(5):\n",
        "#  plt.imshow(X_train_23[i,:,:])\n",
        "#  plt.show()\n",
        "#  print(y_train_23[i])\n",
        "#for i in range(5):\n",
        "#  plt.imshow(X_train_45[i,:,:])\n",
        "#  plt.show()\n",
        "#  print(y_train_45[i])\n",
        "#for i in range(5):\n",
        "#  plt.imshow(X_train_67[i,:,:])\n",
        "#  plt.show()\n",
        "#  print(y_train_67[i])\n",
        "#for i in range(5):\n",
        "#  plt.imshow(X_train_89[i,:,:])\n",
        "#  plt.show()\n",
        "#  print(y_train_89[i])\n",
        "\n",
        "\n",
        "\n",
        "X_train = MNIST_train.data\n",
        "y_train = MNIST_train.targets\n",
        "X_test = MNIST_test.data\n",
        "y_test = MNIST_test.targets\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_indices_01 = []\n",
        "train_indices_23 = []\n",
        "train_indices_45 = []\n",
        "train_indices_67 = []\n",
        "train_indices_89 = []\n",
        "test_indices_01 = []\n",
        "test_indices_23 = []\n",
        "test_indices_45 = []\n",
        "test_indices_67 = []\n",
        "test_indices_89 = []\n",
        "for i in range(len(y_train)):\n",
        "  if y_train[i] == 0 or y_train[i] == 1:\n",
        "    train_indices_01.append(i)\n",
        "  elif y_train[i] == 2 or y_train[i] == 3:\n",
        "    train_indices_23.append(i)\n",
        "  elif y_train[i] == 4 or y_train[i] == 5:\n",
        "    train_indices_45.append(i)\n",
        "  elif y_train[i] == 6 or y_train[i] == 7:\n",
        "    train_indices_67.append(i)\n",
        "  elif y_train[i] == 8 or y_train[i] == 9:\n",
        "    train_indices_89.append(i)\n",
        "  \n",
        "\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  if y_test[i] == 0 or y_test[i] == 1:\n",
        "    test_indices_01.append(i)\n",
        "  elif y_test[i] == 2 or y_test[i]== 3:\n",
        "    test_indices_23.append(i)\n",
        "  elif y_test[i] == 4 or y_test[i] == 5:\n",
        "    test_indices_45.append(i)\n",
        "  elif y_test[i] == 6 or y_test[i] == 7:\n",
        "    test_indices_67.append(i)\n",
        "  elif y_test[i] == 8 or y_test[i] == 9:\n",
        "    test_indices_89.append(i)\n",
        "\n",
        "\n",
        "\n",
        "X_train_01 = X_train[train_indices_01]\n",
        "y_train_01 = y_train[train_indices_01]\n",
        "X_test_01 = X_test[test_indices_01]\n",
        "y_test_01 = y_test[test_indices_01]\n",
        "\n",
        "X_train_23 = X_train[train_indices_23]\n",
        "y_train_23 = y_train[train_indices_23]\n",
        "X_test_23 = X_test[test_indices_23]\n",
        "y_test_23 = y_test[test_indices_23]\n",
        "\n",
        "X_train_45 = X_train[train_indices_45]\n",
        "y_train_45 = y_train[train_indices_45]\n",
        "X_test_45 = X_test[test_indices_45]\n",
        "y_test_45 = y_test[test_indices_45]\n",
        "\n",
        "X_train_67 = X_train[train_indices_67]\n",
        "y_train_67 = y_train[train_indices_67]\n",
        "X_test_67 = X_test[test_indices_67]\n",
        "y_test_67 = y_test[test_indices_67]\n",
        "\n",
        "X_train_89 = X_train[train_indices_89]\n",
        "y_train_89 = y_train[train_indices_89]\n",
        "X_test_89 = X_test[test_indices_89]\n",
        "y_test_89 = y_test[test_indices_89]\n",
        "\n",
        "\n",
        "X_test_01 = X_test_01.to(device)\n",
        "print(type(y_train_01))\n",
        "print(y_train_01[0])\n",
        "\n",
        "\n",
        "X_train = X_train.unsqueeze(1).float()\n",
        "X_test = X_test.unsqueeze(1).float()\n",
        "\n",
        "X_train_01 = X_train_01.unsqueeze(1).float()\n",
        "X_test_01 = X_test_01.unsqueeze(1).float()\n",
        "\n",
        "X_train_23 = X_train_23.unsqueeze(1).float()\n",
        "X_test_23 = X_test_23.unsqueeze(1).float()\n",
        "\n",
        "X_train_45 = X_train_45.unsqueeze(1).float()\n",
        "X_test_45 = X_test_45.unsqueeze(1).float()\n",
        "\n",
        "X_train_67 = X_train_67.unsqueeze(1).float()\n",
        "X_test_67 = X_test_67.unsqueeze(1).float()\n",
        "\n",
        "X_train_89 = X_train_89.unsqueeze(1).float()\n",
        "X_test_89 = X_test_89.unsqueeze(1).float()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-50fhYHMZlx"
      },
      "source": [
        "class YannLecun(torch.nn.Module):\n",
        "  def __init__(self,activation = 'leaky relu', pooling = 'max', conv_size = 3, use_batch_norm = False, use_dropout = False):\n",
        "    super(YannLecun, self).__init__()\n",
        "    self.conv_size = conv_size\n",
        "    self.use_batch_norm = use_batch_norm\n",
        "    self.use_dropout = use_dropout\n",
        "\n",
        "    if activation == 'relu':\n",
        "      activation_function = torch.nn.ReLU()\n",
        "    elif activation == 'tanh':\n",
        "      activation_function = torch.nn.Tanh()\n",
        "    elif activation == 'leaky relu':\n",
        "        activation_function = torch.nn.LeakyReLU()\n",
        "    else:\n",
        "      raise NotImplementedError   \n",
        "\n",
        "    if pooling == 'max':\n",
        "      pooling_layer = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    elif pooling == 'avg':\n",
        "      pooling_layer = torch.nn.AvgPool2d(kernel_size = 2, stride = 2)\n",
        "    else:\n",
        "      raise NotImplementedError   \n",
        "    \n",
        "    if conv_size == 3:\n",
        "      self.conv1_1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, padding= 1)\n",
        "      self.conv1_2 = torch.nn.Conv2d(in_channels=6, out_channels=6, kernel_size=3, padding= 1)\n",
        "    elif conv_size == 5:\n",
        "      self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding= 2)\n",
        "    else:\n",
        "      raise NotImplementedError\n",
        "    \n",
        "    self.act1 = activation_function\n",
        "    self.bn1 = torch.nn.BatchNorm2d(num_features = 6)\n",
        "    self.pool1 = pooling_layer\n",
        "    self.dp1 = torch.nn.Dropout(p = 0.25) \n",
        "\n",
        "    if conv_size == 3:\n",
        "      self.conv2_1 = torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, padding= 0)\n",
        "      self.conv2_2 = torch.nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding= 0)\n",
        "    elif conv_size == 5:\n",
        "      self.conv2 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding= 0)\n",
        "    else:\n",
        "      raise NotImplementedError\n",
        "\n",
        "    self.act2 = activation_function\n",
        "    self.bn2 = torch.nn.BatchNorm2d(num_features = 16)\n",
        "    self.pool2 = pooling_layer\n",
        "    self.dp2 = torch.nn.Dropout(p = 0.25) \n",
        "\n",
        "    self.fc1 = torch.nn.Linear(5*5*16, 120)\n",
        "    self.act3 = torch.nn.Tanh()\n",
        "    self.dp3 = torch.nn.Dropout(p = 0.5) \n",
        "\n",
        "    self.fc2 = torch.nn.Linear(120,84)\n",
        "    self.act4 = torch.nn.Tanh()\n",
        "    self.dp4 = torch.nn.Dropout(p = 0.5) \n",
        "\n",
        "    self.fc3 = torch.nn.Linear(84,10)\n",
        "    self.act5 = torch.nn.Softmax()\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    if self.conv_size == 3:\n",
        "      x = self.conv1_1(x)\n",
        "      x = self.conv1_2(x)\n",
        "    elif self.conv_size == 5:\n",
        "      x = self.conv1(x)\n",
        "\n",
        "    x = self.act1(x)\n",
        "    if self.use_batch_norm:\n",
        "      x = self.bn1(x)\n",
        "    x = self.pool1(x)\n",
        "    if self.use_dropout:\n",
        "      x = self.dp1(x)\n",
        "\n",
        "\n",
        "    if self.conv_size == 3:\n",
        "      x = self.conv2_1(x)\n",
        "      x = self.conv2_2(x)\n",
        "    elif self.conv_size == 5:\n",
        "      x = self.conv2(x)\n",
        "    \n",
        "    x = self.act2(x)\n",
        "    if self.use_batch_norm:\n",
        "      x = self.bn2(x)\n",
        "    x = self.pool2(x)\n",
        "    if self.use_dropout:\n",
        "      x = self.dp2(x)\n",
        "\n",
        "    x = x.view(x.size(0),x.size(1)*x.size(2)*x.size(3))\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = self.act3(x)\n",
        "    if self.use_dropout:\n",
        "      x = self.dp3(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.act4(x)\n",
        "    if self.use_dropout:\n",
        "      x = self.dp4(x)\n",
        "    x = self.fc3(x)\n",
        "    x = self.act5(x)\n",
        "    \n",
        "    x = x.to(device)\n",
        "\n",
        "    return x\n",
        "\n",
        "yann_lecun = YannLecun(use_batch_norm = True, use_dropout =True)\n",
        "yann_lecun = yann_lecun.to(device)\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "my_optimizer = torch.optim.Adam(yann_lecun.parameters(), lr=4.0e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtWm8sFKkCyk"
      },
      "source": [
        "def variable(t: torch.Tensor, use_cuda=True, **kwargs): #переменная тупо для того, чтобы можно было дифференцировать по ним.\n",
        "    if torch.cuda.is_available() and use_cuda:          #в нашем случае в самом тензоре есть requires_grad если True то переменная\n",
        "        t = t.cuda()\n",
        "    return Variable(t, **kwargs)\n",
        "\n",
        "\n",
        "class EWC(object):\n",
        "    def __init__(self, old_x, old_y = None, model = yann_lecun):\n",
        "\n",
        "        self.model = model\n",
        "        self.old_x = old_x # по сути иксы\n",
        "        self.old_y = old_y\n",
        "        self.params = {n: p for n, p in self.model.named_parameters() if p.requires_grad} #собирает в словарь имя:параметры\n",
        "        self._old_params = {}\n",
        "        self._precision_matrices = self._diag_fisher() \n",
        "\n",
        "        for n, p in deepcopy(self.params).items():\n",
        "            self._old_params[n] = variable(p.data)\n",
        "\n",
        "\n",
        "    def _diag_fisher(self):\n",
        "        precision_matrices = {}\n",
        "        for n, p in deepcopy(self.params).items(): #копируем параметры через дип копи чтоб не поменять их\n",
        "            p.data.zero_() #все параметры скопированные зануляем\n",
        "            precision_matrices[n] = variable(p.data) #выставляем requires_grad = True \n",
        "\n",
        "        self.model.eval() #переводим в состояние evaluation\n",
        "        #for input in self.dataset:\n",
        "        self.model.zero_grad() #как обычно чтоб не накапливался градиент зануляем вначале\n",
        "        self.old_x = variable(self.old_x) #input requires grad = True\n",
        "        output = self.model(self.old_x)#.view(1, -1)\n",
        "        output = output.to(device)\n",
        "        loss = F.nll_loss(F.log_softmax(output, dim=1), self.old_y)\n",
        "        loss.backward()\n",
        "\n",
        "        for n, p in self.model.named_parameters():\n",
        "            #print(f\"p grad data shape = {p.grad.data.shape}\")\n",
        "            precision_matrices[n].data += p.grad.data ** 2 / len(self.old_x) #то, чточ делим на число это типа матожидание берем\n",
        "\n",
        "        precision_matrices = {n: p for n, p in precision_matrices.items()}\n",
        "        return precision_matrices\n",
        "\n",
        "    def penalty(self, model: nn.Module):\n",
        "        loss = 0\n",
        "        for n, p in model.named_parameters():\n",
        "            _loss = self._precision_matrices[n].data * (p - self._old_params[n].data) ** 2\n",
        "            loss += _loss.sum()\n",
        "        return loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFGcXBokf_wi"
      },
      "source": [
        "def test_accuracy(x_test, y_test):\n",
        "    x_test = x_test.to(device)\n",
        "    test_preds = yann_lecun.forward(x_test)\n",
        "    test_preds = test_preds.to(device)\n",
        "    y_test = y_test.to(device)\n",
        "    accuracy = (test_preds.argmax(dim = 1) == y_test).float().mean().data.cpu()\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI-6IaRJWnAS"
      },
      "source": [
        "def normal_train(X_trains, y_trains, X_tests, y_tests, model = yann_lecun, optimizer = my_optimizer, epochs = 5, batch_sizes = 100):\n",
        "    model.train() #выставляем, что она меняет свои коэф\n",
        "    batch_size = batch_sizes\n",
        "    test_accuracy_history = []\n",
        "    test_loss_history = []\n",
        "\n",
        "    X_tests = X_tests.to(device)\n",
        "    y_tests = y_tests.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        order = np.random.permutation(len(X_trains))\n",
        "        for start_index in range(0,len(X_trains), batch_size):\n",
        "            batch_indexes = order[start_index:start_index+batch_size]\n",
        "\n",
        "            X_batch = X_trains[batch_indexes].to(device)\n",
        "            y_batch = y_trains[batch_indexes].to(device)\n",
        "\n",
        "            X_batch, y_batch = variable(X_batch), variable(y_batch)\n",
        "            optimizer.zero_grad()\n",
        "            preds = model.forward(X_batch)\n",
        "            loss_value = loss(preds, y_batch)\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        test_preds = model.forward(X_tests)\n",
        "        test_loss_history.append(loss(test_preds, y_tests).data.cpu())\n",
        "\n",
        "        accuracy = (test_preds.argmax(dim = 1) == y_tests).float().mean().data.cpu()\n",
        "        test_accuracy_history.append(accuracy)\n",
        "        print(accuracy)  \n",
        "\n",
        "\n",
        "def ewc_train(X_trains, y_trains, X_tests, y_tests, old_x_test, old_y_test, number, \n",
        "              ewc: EWC, importance, epochs = 0, model = yann_lecun, optimizer = my_optimizer, batch_sizes = 100):\n",
        "    model.train() #выставляем, что она меняет свои коэф\n",
        "    #epoch_loss = 0\n",
        "    batch_size = batch_sizes\n",
        "    test_accuracy_history = []\n",
        "    test_loss_history = []\n",
        "\n",
        "    X_tests = X_tests.to(device)\n",
        "    y_tests = y_tests.to(device)\n",
        "    temp_epoch = 1\n",
        "    while True:\n",
        "        order = np.random.permutation(len(X_trains))\n",
        "        for start_index in range(0,len(X_trains), batch_size):\n",
        "            batch_indexes = order[start_index:start_index+batch_size]\n",
        "\n",
        "            X_batch = X_trains[batch_indexes].to(device)\n",
        "            y_batch = y_trains[batch_indexes].to(device)\n",
        "\n",
        "            X_batch, y_batch = variable(X_batch), variable(y_batch)\n",
        "            optimizer.zero_grad()\n",
        "            preds = model.forward(X_batch)\n",
        "            loss_value = loss(preds, y_batch) + importance * ewc.penalty(model)\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        test_preds = model.forward(X_tests)\n",
        "        test_loss_history.append(loss(test_preds, y_tests).data.cpu())\n",
        "\n",
        "        accuracy = (test_preds.argmax(dim = 1) == y_tests).float().mean().data.cpu()\n",
        "        test_accuracy_history.append(accuracy)\n",
        "        old_accuracy = test_accuracy(old_x_test, old_y_test)\n",
        "        print('accuracy on current task: ',accuracy)\n",
        "        print('accuracy on old task: ', old_accuracy)\n",
        "        if number == 1:\n",
        "            print('accuracy on 01: ', test_accuracy(X_test_01,y_test_01),'\\n')\n",
        "        elif number == 2:\n",
        "            print('accuracy on 01: ', test_accuracy(X_test_01,y_test_01))\n",
        "            print('accuracy on 23: ', test_accuracy(X_test_23,y_test_23),'\\n')\n",
        "        elif number == 3:\n",
        "            print('accuracy on 01: ', test_accuracy(X_test_01,y_test_01))\n",
        "            print('accuracy on 23: ', test_accuracy(X_test_23,y_test_23))\n",
        "            print('accuracy on 45: ', test_accuracy(X_test_45,y_test_45),'\\n')\n",
        "        elif number == 4:\n",
        "            print('accuracy on 01: ', test_accuracy(X_test_01,y_test_01))\n",
        "            print('accuracy on 23: ', test_accuracy(X_test_23,y_test_23))\n",
        "            print('accuracy on 45: ', test_accuracy(X_test_45,y_test_45))\n",
        "            print('accuracy on 67: ', test_accuracy(X_test_67,y_test_67),'\\n')\n",
        "\n",
        "        if temp_epoch == epochs:\n",
        "            break\n",
        "        temp_epoch += 1\n",
        "        if (accuracy >= old_accuracy or (abs(accuracy - old_accuracy) <= 0.05 and number == 1) or abs(accuracy - old_accuracy) <= 0.03) and epochs == 0:\n",
        "            break\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSx3UVk9wE3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92b6de68-7d11-408e-abdf-682ffcec4b0d"
      },
      "source": [
        "pytorch_total_params = sum(p.numel() for p in yann_lecun.parameters())\n",
        "print(pytorch_total_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "62768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K48aBN6oUVS4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cd748f2-47ac-496f-968c-56a85bacc1f9"
      },
      "source": [
        "normal_train(X_train_01,y_train_01,X_test_01,y_test_01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(0.9981)\n",
            "tensor(0.9986)\n",
            "tensor(1.)\n",
            "tensor(1.)\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbfayncHEit3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa633d17-6446-4778-befe-1419c5534490"
      },
      "source": [
        "old_tasks = X_train_01\n",
        "old_y = y_train_01\n",
        "old_x_test = X_test_01\n",
        "old_y_test = y_test_01\n",
        "old_y = old_y.to(device)\n",
        "my_ewc = EWC(old_tasks, old_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPuKGfAzsjEu",
        "outputId": "5de419fb-0aa0-4066-992f-a71276542981"
      },
      "source": [
        "ewc_train(X_train_23,y_train_23,X_test_23,y_test_23,old_x_test, old_y_test,1, my_ewc, importance = 0.8e15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy on current task:  tensor(0.)\n",
            "accuracy on old task:  tensor(1.)\n",
            "accuracy on 01:  tensor(0.9986) \n",
            "\n",
            "accuracy on current task:  tensor(0.)\n",
            "accuracy on old task:  tensor(0.9995)\n",
            "accuracy on 01:  tensor(0.9991) \n",
            "\n",
            "accuracy on current task:  tensor(0.)\n",
            "accuracy on old task:  tensor(0.9986)\n",
            "accuracy on 01:  tensor(1.) \n",
            "\n",
            "accuracy on current task:  tensor(0.)\n",
            "accuracy on old task:  tensor(0.9991)\n",
            "accuracy on 01:  tensor(0.9995) \n",
            "\n",
            "accuracy on current task:  tensor(0.)\n",
            "accuracy on old task:  tensor(0.9995)\n",
            "accuracy on 01:  tensor(0.9991) \n",
            "\n",
            "accuracy on current task:  tensor(0.)\n",
            "accuracy on old task:  tensor(1.)\n",
            "accuracy on 01:  tensor(1.) \n",
            "\n",
            "accuracy on current task:  tensor(0.)\n",
            "accuracy on old task:  tensor(0.9995)\n",
            "accuracy on 01:  tensor(1.) \n",
            "\n",
            "accuracy on current task:  tensor(0.)\n",
            "accuracy on old task:  tensor(0.9995)\n",
            "accuracy on 01:  tensor(0.9995) \n",
            "\n",
            "accuracy on current task:  tensor(0.)\n",
            "accuracy on old task:  tensor(0.9991)\n",
            "accuracy on 01:  tensor(0.9986) \n",
            "\n",
            "accuracy on current task:  tensor(0.)\n",
            "accuracy on old task:  tensor(0.9995)\n",
            "accuracy on 01:  tensor(0.9995) \n",
            "\n",
            "accuracy on current task:  tensor(0.)\n",
            "accuracy on old task:  tensor(0.9995)\n",
            "accuracy on 01:  tensor(1.) \n",
            "\n",
            "accuracy on current task:  tensor(0.)\n",
            "accuracy on old task:  tensor(1.)\n",
            "accuracy on 01:  tensor(0.9986) \n",
            "\n",
            "accuracy on current task:  tensor(0.)\n",
            "accuracy on old task:  tensor(1.)\n",
            "accuracy on 01:  tensor(0.9995) \n",
            "\n",
            "accuracy on current task:  tensor(0.)\n",
            "accuracy on old task:  tensor(0.9986)\n",
            "accuracy on 01:  tensor(0.9995) \n",
            "\n",
            "accuracy on current task:  tensor(0.8653)\n",
            "accuracy on old task:  tensor(0.4515)\n",
            "importance =  1600000000000000.0\n",
            "accuracy on 01:  tensor(0.4383) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9j49hGLta-A",
        "outputId": "9329153e-30ba-4bc0-a613-3241fd47f729"
      },
      "source": [
        "ewc_train(X_train_23,y_train_23,X_test_23,y_test_23,old_x_test, old_y_test, 1, my_ewc, epochs = 1, importance = 8e15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy on current task:  tensor(0.7605)\n",
            "accuracy on old task:  tensor(0.4563)\n",
            "accuracy on 01:  tensor(0.4657) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rspO-raMwwpc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34af04db-804c-482c-ddc0-1912c8b68cb1"
      },
      "source": [
        "print(f\"Accuracy on 01: {test_accuracy(old_x_test, old_y_test)}\")\n",
        "cur_x_test = X_test_23\n",
        "cur_x_test = cur_x_test.to(device)\n",
        "cur_y_test = y_test_23\n",
        "\n",
        "print(f\"Accuracy on 23: {test_accuracy(cur_x_test, cur_y_test)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4742)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nCuYHe_W2hP"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chTncMZy8tJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34dae8e6-592d-4b43-8be6-c0f591b8dadd"
      },
      "source": [
        "old_tasks = torch.cat((old_tasks,X_train_23))\n",
        "old_x_test = torch.cat((old_x_test, cur_x_test))\n",
        "old_y_test = torch.cat((old_y_test,cur_y_test))\n",
        "y_train_23 = y_train_23.to(device)\n",
        "old_y = torch.cat((old_y, y_train_23))\n",
        "old_y = old_y.to(device)\n",
        "my_ewc = EWC(old_tasks, old_y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6GS0MEksmHs",
        "outputId": "69b04c55-7b44-4e3f-b294-c15f995b4c31"
      },
      "source": [
        "ewc_train(X_train_45,y_train_45,X_test_45,y_test_45, old_x_test, old_y_test, 2, my_ewc, importance = 6e11)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy on current task:  tensor(0.0059)\n",
            "accuracy on old task:  tensor(0.6178)\n",
            "accuracy on 01:  tensor(0.4610)\n",
            "accuracy on 23:  tensor(0.7644) \n",
            "\n",
            "accuracy on current task:  tensor(0.0048)\n",
            "accuracy on old task:  tensor(0.6108)\n",
            "accuracy on 01:  tensor(0.4648)\n",
            "accuracy on 23:  tensor(0.7605) \n",
            "\n",
            "accuracy on current task:  tensor(0.0107)\n",
            "accuracy on old task:  tensor(0.6076)\n",
            "accuracy on 01:  tensor(0.4534)\n",
            "accuracy on 23:  tensor(0.7644) \n",
            "\n",
            "accuracy on current task:  tensor(0.0112)\n",
            "accuracy on old task:  tensor(0.6146)\n",
            "accuracy on 01:  tensor(0.4539)\n",
            "accuracy on 23:  tensor(0.7747) \n",
            "\n",
            "accuracy on current task:  tensor(0.0176)\n",
            "accuracy on old task:  tensor(0.6043)\n",
            "accuracy on 01:  tensor(0.4459)\n",
            "accuracy on 23:  tensor(0.7674) \n",
            "\n",
            "accuracy on current task:  tensor(0.0224)\n",
            "accuracy on old task:  tensor(0.6036)\n",
            "accuracy on 01:  tensor(0.4369)\n",
            "accuracy on 23:  tensor(0.7659) \n",
            "\n",
            "accuracy on current task:  tensor(0.0299)\n",
            "accuracy on old task:  tensor(0.6021)\n",
            "accuracy on 01:  tensor(0.4293)\n",
            "accuracy on 23:  tensor(0.7610) \n",
            "\n",
            "accuracy on current task:  tensor(0.0507)\n",
            "accuracy on old task:  tensor(0.5975)\n",
            "accuracy on 01:  tensor(0.4312)\n",
            "accuracy on 23:  tensor(0.7733) \n",
            "\n",
            "accuracy on current task:  tensor(0.0827)\n",
            "accuracy on old task:  tensor(0.5862)\n",
            "accuracy on 01:  tensor(0.4246)\n",
            "accuracy on 23:  tensor(0.7537) \n",
            "\n",
            "accuracy on current task:  tensor(0.0880)\n",
            "accuracy on old task:  tensor(0.5850)\n",
            "accuracy on 01:  tensor(0.4071)\n",
            "accuracy on 23:  tensor(0.7556) \n",
            "\n",
            "accuracy on current task:  tensor(0.1147)\n",
            "accuracy on old task:  tensor(0.5684)\n",
            "accuracy on 01:  tensor(0.4222)\n",
            "accuracy on 23:  tensor(0.7370) \n",
            "\n",
            "accuracy on current task:  tensor(0.1505)\n",
            "accuracy on old task:  tensor(0.5643)\n",
            "accuracy on 01:  tensor(0.4161)\n",
            "accuracy on 23:  tensor(0.7307) \n",
            "\n",
            "accuracy on current task:  tensor(0.1830)\n",
            "accuracy on old task:  tensor(0.5619)\n",
            "accuracy on 01:  tensor(0.4123)\n",
            "accuracy on 23:  tensor(0.6910) \n",
            "\n",
            "accuracy on current task:  tensor(0.2247)\n",
            "accuracy on old task:  tensor(0.5550)\n",
            "accuracy on 01:  tensor(0.4085)\n",
            "accuracy on 23:  tensor(0.7086) \n",
            "\n",
            "accuracy on current task:  tensor(0.2588)\n",
            "accuracy on old task:  tensor(0.5391)\n",
            "accuracy on 01:  tensor(0.4080)\n",
            "accuracy on 23:  tensor(0.6876) \n",
            "\n",
            "accuracy on current task:  tensor(0.2812)\n",
            "accuracy on old task:  tensor(0.5210)\n",
            "accuracy on 01:  tensor(0.3868)\n",
            "accuracy on 23:  tensor(0.6734) \n",
            "\n",
            "accuracy on current task:  tensor(0.3106)\n",
            "accuracy on old task:  tensor(0.5225)\n",
            "accuracy on 01:  tensor(0.3816)\n",
            "accuracy on 23:  tensor(0.6464) \n",
            "\n",
            "accuracy on current task:  tensor(0.3170)\n",
            "accuracy on old task:  tensor(0.5035)\n",
            "accuracy on 01:  tensor(0.3877)\n",
            "accuracy on 23:  tensor(0.6234) \n",
            "\n",
            "accuracy on current task:  tensor(0.3538)\n",
            "accuracy on old task:  tensor(0.4960)\n",
            "accuracy on 01:  tensor(0.3953)\n",
            "accuracy on 23:  tensor(0.6161) \n",
            "\n",
            "accuracy on current task:  tensor(0.3874)\n",
            "accuracy on old task:  tensor(0.4876)\n",
            "accuracy on 01:  tensor(0.3669)\n",
            "accuracy on 23:  tensor(0.5901) \n",
            "\n",
            "accuracy on current task:  tensor(0.3906)\n",
            "accuracy on old task:  tensor(0.4883)\n",
            "accuracy on 01:  tensor(0.3806)\n",
            "accuracy on 23:  tensor(0.5906) \n",
            "\n",
            "accuracy on current task:  tensor(0.4104)\n",
            "accuracy on old task:  tensor(0.4732)\n",
            "accuracy on 01:  tensor(0.3579)\n",
            "accuracy on 23:  tensor(0.5857) \n",
            "\n",
            "accuracy on current task:  tensor(0.4440)\n",
            "accuracy on old task:  tensor(0.4645)\n",
            "accuracy on 01:  tensor(0.3579)\n",
            "accuracy on 23:  tensor(0.5583) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHHWUqa6unVh",
        "outputId": "c1f74235-7a52-4a14-ed26-b5e833052f71"
      },
      "source": [
        "ewc_train(X_train_45,y_train_45,X_test_45,y_test_45, old_x_test, old_y_test, 2, my_ewc, epochs = 1, importance = 8e11)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy on current task:  tensor(0.4125)\n",
            "accuracy on old task:  tensor(0.3827)\n",
            "accuracy on 01:  tensor(0.3196)\n",
            "accuracy on 23:  tensor(0.4285) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMCrkfsFoeTi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d774d1d7-b764-42fc-fc10-a3541ea6b5ce"
      },
      "source": [
        "cur_x_test = X_test_45\n",
        "cur_y_test = y_test_45\n",
        "print(f\"Accuracy on 45: {test_accuracy(cur_x_test, cur_y_test)}\")\n",
        "old_x_test = torch.cat((old_x_test,cur_x_test.to(device)))\n",
        "old_y_test = torch.cat((old_y_test,cur_y_test))\n",
        "print(f\"Accuracy on 012345: {test_accuracy(old_x_test, old_y_test)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4018)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAxKQAW4ybKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12ae5374-1b4b-4928-87ec-1de608357c10"
      },
      "source": [
        "old_tasks = torch.cat((old_tasks,X_train_45))\n",
        "y_train_45 = y_train_45.to(device)\n",
        "old_y = torch.cat((old_y, y_train_45))\n",
        "old_y = old_y.to(device)\n",
        "my_ewc = EWC(old_tasks, old_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBoVzXjAsoWy",
        "outputId": "3ca9eade-2a50-45a2-c562-085a95ab5ca9"
      },
      "source": [
        "ewc_train(X_train_67,y_train_67,X_test_67,y_test_67, old_x_test, old_y_test, 3, my_ewc, importance = 4e11)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy on current task:  tensor(0.0645)\n",
            "accuracy on old task:  tensor(0.4484)\n",
            "accuracy on 01:  tensor(0.3626)\n",
            "accuracy on 23:  tensor(0.5416)\n",
            "accuracy on 45:  tensor(0.4328) \n",
            "\n",
            "accuracy on current task:  tensor(0.1012)\n",
            "accuracy on old task:  tensor(0.4334)\n",
            "accuracy on 01:  tensor(0.3579)\n",
            "accuracy on 23:  tensor(0.5225)\n",
            "accuracy on 45:  tensor(0.4434) \n",
            "\n",
            "accuracy on current task:  tensor(0.1289)\n",
            "accuracy on old task:  tensor(0.4149)\n",
            "accuracy on 01:  tensor(0.3570)\n",
            "accuracy on 23:  tensor(0.4922)\n",
            "accuracy on 45:  tensor(0.3895) \n",
            "\n",
            "accuracy on current task:  tensor(0.1848)\n",
            "accuracy on old task:  tensor(0.4162)\n",
            "accuracy on 01:  tensor(0.3480)\n",
            "accuracy on 23:  tensor(0.4853)\n",
            "accuracy on 45:  tensor(0.3559) \n",
            "\n",
            "accuracy on current task:  tensor(0.2407)\n",
            "accuracy on old task:  tensor(0.3973)\n",
            "accuracy on 01:  tensor(0.3470)\n",
            "accuracy on 23:  tensor(0.4868)\n",
            "accuracy on 45:  tensor(0.3618) \n",
            "\n",
            "accuracy on current task:  tensor(0.2971)\n",
            "accuracy on old task:  tensor(0.3757)\n",
            "accuracy on 01:  tensor(0.3300)\n",
            "accuracy on 23:  tensor(0.4407)\n",
            "accuracy on 45:  tensor(0.3191) \n",
            "\n",
            "accuracy on current task:  tensor(0.3555)\n",
            "accuracy on old task:  tensor(0.3676)\n",
            "accuracy on 01:  tensor(0.3291)\n",
            "accuracy on 23:  tensor(0.4569)\n",
            "accuracy on 45:  tensor(0.3068) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqd6P92hvPXA",
        "outputId": "1fa62f10-35c8-4a12-aac5-4ca6d16df548"
      },
      "source": [
        "ewc_train(X_train_67,y_train_67,X_test_67,y_test_67, old_x_test, old_y_test, 3, my_ewc, epochs = 1, importance = 6e11)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy on current task:  tensor(0.3862)\n",
            "accuracy on old task:  tensor(0.3038)\n",
            "accuracy on 01:  tensor(0.3007)\n",
            "accuracy on 23:  tensor(0.3310)\n",
            "accuracy on 45:  tensor(0.2006) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5shMU9s-oqhL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48d967b4-3413-4af4-a08b-7a6d217e5c43"
      },
      "source": [
        "cur_x_test = X_test_67\n",
        "cur_y_test = y_test_67\n",
        "print(f\"Accuracy on 67: {test_accuracy(cur_x_test, cur_y_test)}\")\n",
        "\n",
        "old_x_test = torch.cat((old_x_test,cur_x_test.to(device)))\n",
        "old_y_test = torch.cat((old_y_test,cur_y_test))\n",
        "print(f\"Accuracy on 01234567: {test_accuracy(old_x_test, old_y_test)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3666)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcS-zv901n1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5cead13-3799-49a6-9f2d-704c2c83966e"
      },
      "source": [
        "old_tasks = torch.cat((old_tasks,X_train_67))\n",
        "y_train_67 = y_train_67.to(device)\n",
        "old_y = torch.cat((old_y, y_train_67))\n",
        "old_y = old_y.to(device)\n",
        "my_ewc = EWC(old_tasks, old_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3IeDnaEsrHd",
        "outputId": "0b2efdae-4504-403b-bd9f-6c3f93440d8f"
      },
      "source": [
        "ewc_train(X_train_89,y_train_89,X_test_89,y_test_89,old_x_test, old_y_test, 4, my_ewc, importance = 4e11)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy on current task:  tensor(0.0540)\n",
            "accuracy on old task:  tensor(0.3647)\n",
            "accuracy on 01:  tensor(0.3362)\n",
            "accuracy on 23:  tensor(0.4638)\n",
            "accuracy on 45:  tensor(0.2919)\n",
            "accuracy on 67:  tensor(0.3484) \n",
            "\n",
            "accuracy on current task:  tensor(0.1346)\n",
            "accuracy on old task:  tensor(0.3416)\n",
            "accuracy on 01:  tensor(0.3206)\n",
            "accuracy on 23:  tensor(0.4833)\n",
            "accuracy on 45:  tensor(0.2364)\n",
            "accuracy on 67:  tensor(0.3167) \n",
            "\n",
            "accuracy on current task:  tensor(0.2910)\n",
            "accuracy on old task:  tensor(0.3092)\n",
            "accuracy on 01:  tensor(0.2879)\n",
            "accuracy on 23:  tensor(0.4270)\n",
            "accuracy on 45:  tensor(0.2086)\n",
            "accuracy on 67:  tensor(0.2684) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uj11cZCKvirL",
        "outputId": "5c6fb7f7-93dd-4b68-8324-6eb376c9de66"
      },
      "source": [
        "ewc_train(X_train_89,y_train_89,X_test_89,y_test_89,old_x_test, old_y_test, 4, my_ewc, epochs = 1, importance = 32e11)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy on current task:  tensor(0.3449)\n",
            "accuracy on old task:  tensor(0.2092)\n",
            "accuracy on 01:  tensor(0.2690)\n",
            "accuracy on 23:  tensor(0.2449)\n",
            "accuracy on 45:  tensor(0.1041)\n",
            "accuracy on 67:  tensor(0.1858) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AyGmKICy4qj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9xE0wSK2Nd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "573aa110-5a96-4deb-954f-9226c0c6b8c3"
      },
      "source": [
        "cur_x_test = X_test_89\n",
        "cur_y_test = y_test_89\n",
        "print(f\"Accuracy on 89: {test_accuracy(cur_x_test, cur_y_test)}\")\n",
        "\n",
        "old_x_test = torch.cat((old_x_test,cur_x_test.to(device)))\n",
        "old_y_test = torch.cat((old_y_test,cur_y_test))\n",
        "print(f\"Total accuracy: {test_accuracy(old_x_test, old_y_test)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2557)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZySNmI85grM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a781ef5e-dac7-48c3-e945-9facc0cf6964"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3021)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FWaM8ChpTdv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}